{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fambargh/SAMPLE/blob/master/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUko8bkd7zzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "384e3acc-57c1-466a-da3a-c212031c38cd"
      },
      "source": [
        "pip install Pillow\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFyHKyZ_75b7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0e2862ee-644c-460b-fb4e-c515cd767fa6"
      },
      "source": [
        "pip install scipy==1.1.0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdGBB-rO8T0s",
        "colab_type": "text"
      },
      "source": [
        "version of scipy higher than 1.1.0 can not support imread."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M64trYH8KH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imread\n",
        "from scipy.misc import imread, imresize, imsave\n",
        "import time\n",
        "from scipy import misc, ndimage\n",
        "import random\n",
        "from scipy.signal import medfilt\n",
        "import cv2\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-XYOfT28h6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convlayers():\n",
        "\n",
        "\t\tprint('\\nconvlayers(): Initializing layers')\n",
        "\n",
        "\t\tparameters = []\n",
        "\n",
        "\t\t# normalize input\n",
        "\t\twith tf.name_scope('preprocess') as scope:\n",
        "\t\t\timages = imgs/255 - 0.5\n",
        "\n",
        "\t\twith tf.name_scope('conv1_1') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[3, 3, 1, 8], name='weights1_1')\n",
        "\t\t\tconv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[8], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tconv1_1 = tf.nn.relu(out, name=scope)\n",
        "\t\t\tparameters += [kernel, biases]\n",
        "\n",
        "\t\tpool1 = tf.nn.max_pool(conv1_1,\n",
        "\t\t\t\t\t\t\t   ksize=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   strides=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   padding='SAME',\n",
        "\t\t\t\t\t\t\t   name='pool1')\n",
        "\n",
        "\t\tdropout1 = tf.layers.dropout(pool1,\n",
        "\t\t\t                         rate=0.2,\n",
        "\t\t\t                         training=train_mode,\n",
        "\t\t\t                         name='dropout1')\n",
        "\n",
        "\t\twith tf.name_scope('conv1_2') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[3, 3, 8, 16], name='weights1_2')\n",
        "\t\t\tconv = tf.nn.conv2d(dropout1, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[16], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tconv1_2 = tf.nn.relu(out, name=scope)\n",
        "\t\t\tparameters += [kernel, biases]\n",
        "\n",
        "\t\tpool2 = tf.nn.max_pool(conv1_2,\n",
        "\t\t\t\t\t\t\t   ksize=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   strides=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   padding='SAME',\n",
        "\t\t\t\t\t\t\t   name='pool2')\n",
        "\n",
        "\t\tsdropout2 = tf.layers.dropout(pool2,\n",
        "\t\t\t                         rate=0.2,\n",
        "\t\t\t                         training=train_mode,\n",
        "\t\t\t                         name='dropout2')\n",
        "\n",
        "\t\twith tf.name_scope('conv1_3') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[3, 3, 16, 32], name='weights1_3')\n",
        "\t\t\tconv = tf.nn.conv2d(dropout2, kernel, [1, 1, 1, 1], padding='VALID')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[32], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tconv1_3 = tf.nn.relu(out, name=scope)\n",
        "\t\t\tparameters += [kernel, biases]\n",
        "\n",
        "\t\tpool3 = tf.nn.max_pool(conv1_3,\n",
        "\t\t\t\t\t\t\t   ksize=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   strides=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   padding='SAME',\n",
        "\t\t\t\t\t\t\t   name='pool3')\n",
        "\n",
        "\t\tdropout3 = tf.layers.dropout(pool3,\n",
        "\t\t\t                         rate=0.2,\n",
        "\t\t\t                         training=train_mode,\n",
        "\t\t\t                         name='dropout3')\n",
        "\n",
        "\t\twith tf.name_scope('conv1_4') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[1, 1, 32, 16], name='weights1_4')\n",
        "\t\t\tconv = tf.nn.conv2d(dropout3, kernel, [1, 1, 1, 1], padding='VALID')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[16], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tconv1_4 = tf.nn.relu(out, name=scope)\n",
        "\t\t\tparameters += [kernel, biases]\n",
        "\n",
        "\t\twith tf.name_scope('conv1_6') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[1, 1, 16, 2], name='weights1_6')\n",
        "\t\t\tconv = tf.nn.conv2d(conv1_4, kernel, [1, 1, 1, 1], padding='VALID')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[2], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tconv1_6 = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tparameters += [kernel, biases]\n",
        "\n",
        "\t\tsaver = tf.train.Saver({'W1': parameters[0], 'b1': parameters[1], \n",
        "\t\t\t                         'W2': parameters[2], 'b2': parameters[3], \n",
        "\t\t\t                         'W3': parameters[4], 'b3': parameters[5], \n",
        "\t\t\t                         'W4': parameters[6], 'b4': parameters[7], \n",
        "\t\t\t                         'W5': parameters[8], 'b5': parameters[9]})\n",
        "\n",
        "\t\tprint('output: ', np.shape(conv1_6))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP5Pipju8xA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_patches( image, patchshape, overlap_allowed=0.5, cropvalue=None,\n",
        "\t\t\t\t\tcrop_fraction_allowed=0.1):\n",
        "\t\t\"\"\"\n",
        "\t\tGiven an image, extract patches of a given shape with a certain\n",
        "\t\tamount of allowed overlap between patches, using a heuristic to\n",
        "\t\tensure maximum coverage.\n",
        "\t\tIf cropvalue is specified, it is treated as a flag denoting a pixel\n",
        "\t\tthat has been cropped. Patch will be rejected if it has more than\n",
        "\t\tcrop_fraction_allowed * prod(patchshape) pixels equal to cropvalue.\n",
        "\t\tLikewise, patches will be rejected for having more overlap_allowed\n",
        "\t\tfraction of their pixels contained in a patch already selected.\n",
        "\t\t\"\"\"\n",
        "\t\tjump_cols = int(patchshape[1] * overlap_allowed)\n",
        "\t\tjump_rows = int(patchshape[0] * overlap_allowed)\n",
        "\t\t\n",
        "\t\t# Restrict ourselves to the rectangle containing non-cropped pixels\n",
        "\t\tif cropvalue is not None:\n",
        "\t\t\trows, cols = np.where(image != cropvalue)\n",
        "\t\t\trows.sort(); cols.sort()\n",
        "\t\t\tactive =  image[rows[0]:rows[-1], cols[0]:cols[-1]]\n",
        "\t\telse:\n",
        "\t\t\tactive = image\n",
        "\n",
        "\t\trowstart = 0; colstart = 0\n",
        "\n",
        "\t\t# Array tracking where we've already taken patches.\n",
        "\t\tcovered = np.zeros(active.shape, dtype=bool)\n",
        "\t\tpatches = []\n",
        "\n",
        "\t\twhile rowstart < active.shape[0] - patchshape[0]:\n",
        "\t\t\t# Record whether or not e've found a patch in this row, \n",
        "\t\t\t# so we know whether to skip ahead.\n",
        "\t\t\tgot_a_patch_this_row = False\n",
        "\t\t\tcolstart = 0\n",
        "\t\t\twhile colstart < active.shape[1] - patchshape[1]:\n",
        "\t\t\t\t# Slice tuple indexing the region of our proposed patch\n",
        "\t\t\t\tregion = (slice(rowstart, rowstart + patchshape[0]),\n",
        "\t\t\t\t\t\t  slice(colstart, colstart + patchshape[1]))\n",
        "\t\t\t\t\n",
        "\t\t\t\t# The actual pixels in that region.\n",
        "\t\t\t\tpatch = active[region]\n",
        "\n",
        "\t\t\t\t# The current mask value for that region.\n",
        "\t\t\t\tcover_p = covered[region]\n",
        "\t\t\t\tif cropvalue is None or \\\n",
        "\t\t\t\t   frac_eq_to(patch, cropvalue) <= crop_fraction_allowed and \\\n",
        "\t\t\t\t   frac_eq_to(cover_p, True) <= overlap_allowed:\n",
        "\t\t\t\t\t# Accept the patch.\n",
        "\t\t\t\t\tpatches.append(patch)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t# Mask the area.\n",
        "\t\t\t\t\tcovered[region] = True\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t# Jump ahead in the x direction.\n",
        "\t\t\t\t\tcolstart += jump_cols\n",
        "\t\t\t\t\tgot_a_patch_this_row = True\n",
        "\t\t\t\t\t#print \"Got a patch at %d, %d\" % (rowstart, colstart)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t# Otherwise, shift window across by one pixel.\n",
        "\t\t\t\t\tcolstart += 1\n",
        "\n",
        "\t\t\tif got_a_patch_this_row:\n",
        "\t\t\t\t# Jump ahead in the y direction.\n",
        "\t\t\t\trowstart += jump_rows\n",
        "\t\t\telse:\n",
        "\t\t\t\t# Otherwise, shift the window down by one pixel.\n",
        "\t\t\t\trowstart += 1\n",
        "\n",
        "\t\t\t# Return a 3D array of the patches with the patch index as the first\n",
        "\t\t\t# dimension (so that patch pixels stay contiguous in memory, in a \n",
        "\t\t\t# C-ordered array).\n",
        "\n",
        "\t\treturn np.concatenate([pat[np.newaxis, ...] for pat in patches], axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK2I9-Cy84XM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess( images):\n",
        "\n",
        "\t\tnew_images = []\n",
        "\n",
        "\t\tfor i, img in enumerate(images):\n",
        "\n",
        "\t\t\tclahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(40,40))\n",
        "\t\t\timg = clahe.apply(img)\n",
        "\n",
        "\t\t\timg = cv2.bilateralFilter(img, -1, 20, 20)\n",
        "\n",
        "\t\t\tintensities = medfilt(img, (21, 21))\n",
        "\t\t\tintensities = intensities.astype(np.float32)\n",
        "\t\t\tintensities_smoothed = cv2.bilateralFilter(intensities, -1, 70, 13)\n",
        "\t\t\twidth, height = img.shape\n",
        "\t\t\timg[0:width, 0:height] = img[0:width, 0:height] + (90) - intensities_smoothed[0:width, 0:height]\n",
        "\t\t\tidx = img[:] > 210\n",
        "\t\t\timg[idx] = 18\n",
        "\n",
        "\t\t\tclahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(1,1))\n",
        "\t\t\timg = clahe.apply(img)\n",
        "\n",
        "\t\t\tnew_images.append(img)\n",
        "\n",
        "\t\treturn np.array(new_images)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TYiQ-ME8_TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_test_img( sess, idx, img, gt):\n",
        "\n",
        "\t\ttest = img[np.newaxis, ... ]\n",
        "\n",
        "\t\tpred = sess.run(output, feed_dict={\n",
        "\t\t\t\t\t\t\timgs: test, \n",
        "\t\t\t\t\t\t\ttrain_mode: False\n",
        "\t\t\t\t\t\t})\n",
        "\t\tprint('TEST_set[', idx, ']:')\n",
        "\t\tprint('gr_t: ', gt)\n",
        "\t\tprint('pred: ', pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-eaWv5t9HZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exctract_disc_patches(images, ground_truth):\n",
        "\t\t\"\"\" Exctract patches with zero distance from otic disc. \"\"\"\n",
        "\t\tpatches = []\n",
        "\t\timg_h, img_w = images[0].shape\n",
        "\t\tfor i, img in enumerate(images):\n",
        "\n",
        "\t\t\tcenter_x = int(ground_truth[i,1])\n",
        "\t\t\tcenter_y = int(ground_truth[i,0])\n",
        "\n",
        "\t\t\thalf_win_h = 22\n",
        "\t\t\thalf_win_w = 21\n",
        "\n",
        "\t\t\tx1 = center_x - half_win_w\n",
        "\t\t\ty1 = center_y - half_win_h\n",
        "\n",
        "\t\t\tif x1 < 0:\n",
        "\t\t\t\tx1 = 0\n",
        "\t\t\tif y1 < 0:\n",
        "\t\t\t\ty1 = 0\n",
        "\t\t\tif (x1 + 42) >= img_w:\n",
        "\t\t\t\tx1 = img_w - 42\n",
        "\t\t\tif (y1 + 45) >= img_h:\n",
        "\t\t\t\ty1 = img_h - 45\n",
        "\n",
        "\t\t\tx2 = x1 + 42\n",
        "\t\t\ty2 = y1 + 45\n",
        "\n",
        "\t\t\tpatch = img[y1:y2, x1:x2]\n",
        "\n",
        "\t\t\tpatches.append(patch)\n",
        "\t\t\t#patches.append(ndimage.rotate(patch, 180))\n",
        "\n",
        "\t\treturn np.array(patches)\n",
        "\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yR-CH-U9Ld_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(images_folder, gt_file):\n",
        "\t\timages = []\n",
        "\t\tfor filename in os.listdir(data):\n",
        "\t\t\timg = imread(os.path.join(data, me), mode='L')\n",
        "\t\t\tif img is not None:\n",
        "\t\t\t\timages.append(imresize(img, (201, 233)))\n",
        "\t\ttrain_images = np.array(images)\n",
        "\n",
        "\t\ttrain_output = np.loadtxt(gt_file)\n",
        "      \n",
        "#img='data/me'\n",
        "\t\t# delete images without annotations (values (-1, -1))\n",
        "\t\tindices_to_delete = ~(train_output==-1).any(1)\n",
        "\t\ttrain_images = train_images[indices_to_delete]\n",
        "\t\ttrain_output = train_output[indices_to_delete]\n",
        "\n",
        "\t\t# resize output\n",
        "\t\ttrain_output = np.rint(train_output / 3)\n",
        "\n",
        "\t\treturn train_images, train_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVA3wva_9UOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_patches( images, gt):\n",
        "\t\ttrain_patches = []\n",
        "\t\tpatch_dists = []\t# ground truth distance of a patch from the optic disc\n",
        "\t\tprint(\"Creating patches...\")\n",
        "\t\tfor img_id, img in enumerate(images):\n",
        "\n",
        "\t\t\t# the less overlap allowed, the more patches created\n",
        "\t\t\tpatches = extract_patches(img, (45, 42), overlap_allowed=0.2, cropvalue=None, crop_fraction_allowed=0.1)\n",
        "\t\t\ttrain_patches.extend(patches)\n",
        "\n",
        "\t\t\tfor patch_id, patch in enumerate(patches):\n",
        "\t\t\t\tpatch_x2d = patch_id % 24 # patches in a row\n",
        "\t\t\t\tpatch_y2d = patch_id / 24 # patches in a column              \n",
        "\t\t\t\tmid_x = patch_x2d * 8 + 21 # column step + width/2\n",
        "\t\t\t\tmid_y = patch_y2d * 9 + 23 # row step + height/2\n",
        "\n",
        "\t\t\t\tx_offset = gt[img_id, 1] - mid_x\n",
        "\t\t\t\ty_offset = gt[img_id, 0] - mid_y\n",
        "\n",
        "\t\t\t\toffset = np.array([y_offset, x_offset])\n",
        "\t\t\t\tpatch_dists.append(offset)\n",
        "\n",
        "\t\treturn np.array(train_patches), np.array(patch_dists)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swFLz-2k9Vjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle(images, gt):\n",
        "\t\tshuffle = list(zip(images, gt))\n",
        "\t\trandom.shuffle(shuffle)\n",
        "\t\timages, gt = zip(*shuffle)\n",
        "\n",
        "\t\treturn np.array(images), np.array(gt)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keGlof2f9gYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_test_data():\n",
        "\t\timages_folder = './images/test/'\n",
        "\t\tground_truth = './images/gt_test.txt'\n",
        "\n",
        "\t\ttrain_images, train_output = load_data(images_folder, ground_truth)\n",
        "\t\ttrain_images = preprocess(train_images)\n",
        "\n",
        "\t\tdisc_patches = exctract_disc_patches(train_images, train_output)\n",
        "\t\tzero_dists = np.zeros((len(disc_patches), 2))\n",
        "\t\tprint('Disc patches: ', np.shape(disc_patches))\n",
        "\n",
        "\t\ttrain_images, train_output = make_patches(train_images, train_output)\n",
        "\t\tprint('Orig patches: ', np.shape(train_images))\n",
        "\n",
        "\t\ttrain_output = np.concatenate((train_output, zero_dists), axis=0)\n",
        "\t\ttrain_images = np.concatenate((train_images, disc_patches), axis=0)\n",
        "\n",
        "\t\t# randomly shuffle train array\n",
        "\t\ttrain_images, train_output = shuffle(train_images, train_output)\n",
        "\n",
        "\t\tprint(\"Train samples:\", np.shape(train_images))\n",
        "\t\tprint(\"Output samples:\", np.shape(train_output))\n",
        "\n",
        "\t\t# create tensors\n",
        "\t\ttrain_output = train_output[:, np.newaxis, np.newaxis, : ]\n",
        "\t\ttrain_images = train_images[..., np.newaxis]\n",
        "\n",
        "\t\treturn train_images, train_output\n",
        "\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5hZeQi19mLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}