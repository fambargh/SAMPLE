{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fambargh/SAMPLE/blob/master/Untitled23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVzTOY7CsGMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ca2da8d8-7049-4e5b-873b-ab137a3159b7"
      },
      "source": [
        "pip install Pillow\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8R8lg0Ask8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d7b437da-f07c-4284-ec26-c5b80cac4786"
      },
      "source": [
        "pip install scipy==1.1.0\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFlf7R8islIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.misc import imread, imresize, imsave\n",
        "import time\n",
        "from scipy import misc, ndimage\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "from scipy.signal import medfilt\n",
        "import cv2\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orCjKDA4sv0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31f6b9e7-5766-4e50-ec5b-22d56b009d21"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "715U4PQMsv-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_folder='/content/drive/My Drive/drions/images'\n",
        "#for m in range (1,111):   \n",
        "   # ground_truth='/content/drive/My Drive/drions/ground_truth/image_{}.txt'.format(m)\n",
        "ground_truth='/content/drive/My Drive/anotExpert1_001.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaNxsdPHsGST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class optic_disc_detector:\n",
        "\n",
        "\tdef __init__(self, sess=None):\n",
        "\t\tself.imgs = tf.placeholder(tf.float32, [None, 45, 42, 1])\n",
        "\t\tself.train_mode = tf.placeholder(tf.bool)\n",
        "\t\tself.convlayers()\n",
        "\t\tself.output = self.conv1_6\n",
        "\t\tself.sess = sess\n",
        "\n",
        "\tdef convlayers(self):\n",
        "\n",
        "\t\tprint('\\nconvlayers(): Initializing layers')\n",
        "\n",
        "\t\tself.parameters = []\n",
        "\n",
        "\t\t# normalize input\n",
        "\t\twith tf.name_scope('preprocess') as scope:\n",
        "\t\t\timages = self.imgs/255 - 0.5\n",
        "\n",
        "\t\twith tf.name_scope('conv1_1') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[3, 3, 1, 8], name='weights1_1')\n",
        "\t\t\tconv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[8], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tself.conv1_1 = tf.nn.relu(out, name=scope)\n",
        "\t\t\tself.parameters += [kernel, biases]\n",
        "\n",
        "\t\tself.pool1 = tf.nn.max_pool(self.conv1_1,\n",
        "\t\t\t\t\t\t\t   ksize=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   strides=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   padding='SAME',\n",
        "\t\t\t\t\t\t\t   name='pool1')\n",
        "\n",
        "\t\tself.dropout1 = tf.layers.dropout(self.pool1,\n",
        "\t\t\t                         rate=0.2,\n",
        "\t\t\t                         training=self.train_mode,\n",
        "\t\t\t                         name='dropout1')\n",
        "\n",
        "\t\twith tf.name_scope('conv1_2') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[3, 3, 8, 16], name='weights1_2')\n",
        "\t\t\tconv = tf.nn.conv2d(self.dropout1, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[16], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tself.conv1_2 = tf.nn.relu(out, name=scope)\n",
        "\t\t\tself.parameters += [kernel, biases]\n",
        "\n",
        "\t\tself.pool2 = tf.nn.max_pool(self.conv1_2,\n",
        "\t\t\t\t\t\t\t   ksize=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   strides=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   padding='SAME',\n",
        "\t\t\t\t\t\t\t   name='pool2')\n",
        "\n",
        "\t\tself.dropout2 = tf.layers.dropout(self.pool2,\n",
        "\t\t\t                         rate=0.2,\n",
        "\t\t\t                         training=self.train_mode,\n",
        "\t\t\t                         name='dropout2')\n",
        "\n",
        "\t\twith tf.name_scope('conv1_3') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[3, 3, 16, 32], name='weights1_3')\n",
        "\t\t\tconv = tf.nn.conv2d(self.dropout2, kernel, [1, 1, 1, 1], padding='VALID')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[32], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tself.conv1_3 = tf.nn.relu(out, name=scope)\n",
        "\t\t\tself.parameters += [kernel, biases]\n",
        "\n",
        "\t\tself.pool3 = tf.nn.max_pool(self.conv1_3,\n",
        "\t\t\t\t\t\t\t   ksize=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   strides=[1, 3, 3, 1],\n",
        "\t\t\t\t\t\t\t   padding='SAME',\n",
        "\t\t\t\t\t\t\t   name='pool3')\n",
        "\n",
        "\t\tself.dropout3 = tf.layers.dropout(self.pool3,\n",
        "\t\t\t                         rate=0.2,\n",
        "\t\t\t                         training=self.train_mode,\n",
        "\t\t\t                         name='dropout3')\n",
        "\n",
        "\t\twith tf.name_scope('conv1_4') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[1, 1, 32, 16], name='weights1_4')\n",
        "\t\t\tconv = tf.nn.conv2d(self.dropout3, kernel, [1, 1, 1, 1], padding='VALID')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[16], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tself.conv1_4 = tf.nn.relu(out, name=scope)\n",
        "\t\t\tself.parameters += [kernel, biases]\n",
        "\n",
        "\t\twith tf.name_scope('conv1_6') as scope:\n",
        "\t\t\tkernel = tf.get_variable(initializer=tf.keras.initializers.he_normal(), shape=[1, 1, 16, 2], name='weights1_6')\n",
        "\t\t\tconv = tf.nn.conv2d(self.conv1_4, kernel, [1, 1, 1, 1], padding='VALID')\n",
        "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[2], dtype=tf.float32),\n",
        "\t\t\t\t\t\t\t\t trainable=True, name='biases')\n",
        "\t\t\tself.conv1_6 = tf.nn.bias_add(conv, biases)\n",
        "\t\t\tself.parameters += [kernel, biases]\n",
        "\n",
        "\t\tself.saver = tf.train.Saver({'W1': self.parameters[0], 'b1': self.parameters[1], \n",
        "\t\t\t                         'W2': self.parameters[2], 'b2': self.parameters[3], \n",
        "\t\t\t                         'W3': self.parameters[4], 'b3': self.parameters[5], \n",
        "\t\t\t                         'W4': self.parameters[6], 'b4': self.parameters[7], \n",
        "\t\t\t                         'W5': self.parameters[8], 'b5': self.parameters[9]})\n",
        "\n",
        "\t\tprint('output: ', np.shape(self.conv1_6))\n",
        "\n",
        "\tdef extract_patches(self, image, patchshape, overlap_allowed=0.5, cropvalue=None,\n",
        "\t\t\t\t\tcrop_fraction_allowed=0.1):\n",
        "\t\t\"\"\"\n",
        "\t\tGiven an image, extract patches of a given shape with a certain\n",
        "\t\tamount of allowed overlap between patches, using a heuristic to\n",
        "\t\tensure maximum coverage.\n",
        "\t\tIf cropvalue is specified, it is treated as a flag denoting a pixel\n",
        "\t\tthat has been cropped. Patch will be rejected if it has more than\n",
        "\t\tcrop_fraction_allowed * prod(patchshape) pixels equal to cropvalue.\n",
        "\t\tLikewise, patches will be rejected for having more overlap_allowed\n",
        "\t\tfraction of their pixels contained in a patch already selected.\n",
        "\t\t\"\"\"\n",
        "\t\tjump_cols = int(patchshape[1] * overlap_allowed)\n",
        "\t\tjump_rows = int(patchshape[0] * overlap_allowed)\n",
        "\t\t\n",
        "\t\t# Restrict ourselves to the rectangle containing non-cropped pixels\n",
        "\t\tif cropvalue is not None:\n",
        "\t\t\trows, cols = np.where(image != cropvalue)\n",
        "\t\t\trows.sort(); cols.sort()\n",
        "\t\t\tactive =  image[rows[0]:rows[-1], cols[0]:cols[-1]]\n",
        "\t\telse:\n",
        "\t\t\tactive = image\n",
        "\n",
        "\t\trowstart = 0; colstart = 0\n",
        "\n",
        "\t\t# Array tracking where we've already taken patches.\n",
        "\t\tcovered = np.zeros(active.shape, dtype=bool)\n",
        "\t\tpatches = []\n",
        "\n",
        "\t\twhile rowstart < active.shape[0] - patchshape[0]:\n",
        "\t\t\t# Record whether or not e've found a patch in this row, \n",
        "\t\t\t# so we know whether to skip ahead.\n",
        "\t\t\tgot_a_patch_this_row = False\n",
        "\t\t\tcolstart = 0\n",
        "\t\t\twhile colstart < active.shape[1] - patchshape[1]:\n",
        "\t\t\t\t# Slice tuple indexing the region of our proposed patch\n",
        "\t\t\t\tregion = (slice(rowstart, rowstart + patchshape[0]),\n",
        "\t\t\t\t\t\t  slice(colstart, colstart + patchshape[1]))\n",
        "\t\t\t\t\n",
        "\t\t\t\t# The actual pixels in that region.\n",
        "\t\t\t\tpatch = active[region]\n",
        "\n",
        "\t\t\t\t# The current mask value for that region.\n",
        "\t\t\t\tcover_p = covered[region]\n",
        "\t\t\t\tif cropvalue is None or \\\n",
        "\t\t\t\t   frac_eq_to(patch, cropvalue) <= crop_fraction_allowed and \\\n",
        "\t\t\t\t   frac_eq_to(cover_p, True) <= overlap_allowed:\n",
        "\t\t\t\t\t# Accept the patch.\n",
        "\t\t\t\t\tpatches.append(patch)\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t# Mask the area.\n",
        "\t\t\t\t\tcovered[region] = True\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t# Jump ahead in the x direction.\n",
        "\t\t\t\t\tcolstart += jump_cols\n",
        "\t\t\t\t\tgot_a_patch_this_row = True\n",
        "\t\t\t\t\t#print \"Got a patch at %d, %d\" % (rowstart, colstart)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t# Otherwise, shift window across by one pixel.\n",
        "\t\t\t\t\tcolstart += 1\n",
        "\n",
        "\t\t\tif got_a_patch_this_row:\n",
        "\t\t\t\t# Jump ahead in the y direction.\n",
        "\t\t\t\trowstart += jump_rows\n",
        "\t\t\telse:\n",
        "\t\t\t\t# Otherwise, shift the window down by one pixel.\n",
        "\t\t\t\trowstart += 1\n",
        "\n",
        "\t\t\t# Return a 3D array of the patches with the patch index as the first\n",
        "\t\t\t# dimension (so that patch pixels stay contiguous in memory, in a \n",
        "\t\t\t# C-ordered array).\n",
        "\n",
        "\t\treturn np.concatenate([pat[np.newaxis, ...] for pat in patches], axis=0)\n",
        "\n",
        "\tdef preprocess(self, images):\n",
        "\n",
        "\t\tnew_images = []\n",
        "\n",
        "\t\tfor i, img in enumerate(images):\n",
        "\n",
        "\t\t\tclahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(40,40))\n",
        "\t\t\timg = clahe.apply(img)\n",
        "\n",
        "\t\t\timg = cv2.bilateralFilter(img, -1, 20, 20)\n",
        "\n",
        "\t\t\tintensities = medfilt(img, (21, 21))\n",
        "\t\t\tintensities = intensities.astype(np.float32)\n",
        "\t\t\tintensities_smoothed = cv2.bilateralFilter(intensities, -1, 70, 13)\n",
        "\t\t\twidth, height = img.shape\n",
        "\t\t\timg[0:width, 0:height] = img[0:width, 0:height] + (90) - intensities_smoothed[0:width, 0:height]\n",
        "\t\t\tidx = img[:] > 210\n",
        "\t\t\timg[idx] = 18\n",
        "\n",
        "\t\t\tclahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(1,1))\n",
        "\t\t\timg = clahe.apply(img)\n",
        "\n",
        "\t\t\tnew_images.append(img)\n",
        "\n",
        "\t\treturn np.array(new_images)\n",
        "\n",
        "\tdef eval_test_img(self, sess, idx, img, gt):\n",
        "\n",
        "\t\ttest = img[np.newaxis, ... ]\n",
        "\n",
        "\t\tpred = sess.run(self.output, feed_dict={\n",
        "\t\t\t\t\t\t\tself.imgs: test, \n",
        "\t\t\t\t\t\t\tself.train_mode: False\n",
        "\t\t\t\t\t\t})\n",
        "\t\tprint('TEST_set[', idx, ']:')\n",
        "\t\tprint('gr_t: ', gt)\n",
        "\t\tprint('pred: ', pred)\n",
        "\n",
        "\tdef exctract_disc_patches(self, images, ground_truth):\n",
        "\t\t\"\"\" Exctract patches with zero distance from otic disc. \"\"\"\n",
        "\t\tpatches = []\n",
        "\t\timg_h, img_w = images[0].shape\n",
        "\t\tfor i, img in enumerate(images):\n",
        "\n",
        "\t\t\tcenter_x = int(ground_truth[i,1])\n",
        "\t\t\tcenter_y = int(ground_truth[i,0])\n",
        "\n",
        "\t\t\thalf_win_h = 22\n",
        "\t\t\thalf_win_w = 21\n",
        "\n",
        "\t\t\tx1 = center_x - half_win_w\n",
        "\t\t\ty1 = center_y - half_win_h\n",
        "\n",
        "\t\t\tif x1 < 0:\n",
        "\t\t\t\tx1 = 0\n",
        "\t\t\tif y1 < 0:\n",
        "\t\t\t\ty1 = 0\n",
        "\t\t\tif (x1 + 42) >= img_w:\n",
        "\t\t\t\tx1 = img_w - 42\n",
        "\t\t\tif (y1 + 45) >= img_h:\n",
        "\t\t\t\ty1 = img_h - 45\n",
        "\n",
        "\t\t\tx2 = x1 + 42\n",
        "\t\t\ty2 = y1 + 45\n",
        "\n",
        "\t\t\tpatch = img[y1:y2, x1:x2]\n",
        "\n",
        "\t\t\tpatches.append(patch)\n",
        "\t\t\t#patches.append(ndimage.rotate(patch, 180))\n",
        "\n",
        "\t\treturn np.array(patches)\n",
        "\n",
        "\tdef load_data(self, images_folder, gt_file):\n",
        "\t\timages = []\n",
        "\t\tfor filename in os.listdir(images_folder):\n",
        "\t\t\timg = imread(os.path.join(images_folder, filename), mode='L')\n",
        "\t\t\tif img is not None:\n",
        "\t\t\t\timages.append(imresize(img, (201, 233)))\n",
        "\t\ttrain_images = np.array(images)\n",
        "\n",
        "\t\ttrain_output = np.loadtxt(gt_file)\n",
        "\n",
        "\t\t# delete images without annotations (values (-1, -1))\n",
        "\t\tindices_to_delete = ~(train_output==-1).any(1)\n",
        "\t\ttrain_images = train_images[indices_to_delete]\n",
        "\t\ttrain_output = train_output[indices_to_delete]\n",
        "\n",
        "\t\t# resize output\n",
        "\t\ttrain_output = np.rint(train_output / 3)\n",
        "\n",
        "\t\treturn train_images, train_output\n",
        "\n",
        "\tdef make_patches(self, images, gt):\n",
        "\t\ttrain_patches = []\n",
        "\t\tpatch_dists = []\t# ground truth distance of a patch from the optic disc\n",
        "\t\tprint(\"Creating patches...\")\n",
        "\t\tfor img_id, img in enumerate(images):\n",
        "\n",
        "\t\t\t# the less overlap allowed, the more patches created\n",
        "\t\t\tpatches = self.extract_patches(img, (45, 42), overlap_allowed=0.2, cropvalue=None, crop_fraction_allowed=0.1)\n",
        "\t\t\ttrain_patches.extend(patches)\n",
        "\n",
        "\t\t\tfor patch_id, patch in enumerate(patches):\n",
        "\t\t\t\tpatch_x2d = patch_id % 24 # patches in a row\n",
        "\t\t\t\tpatch_y2d = patch_id / 24 # patches in a column              \n",
        "\t\t\t\tmid_x = patch_x2d * 8 + 21 # column step + width/2\n",
        "\t\t\t\tmid_y = patch_y2d * 9 + 23 # row step + height/2\n",
        "\n",
        "\t\t\t\tx_offset = gt[img_id, 1] - mid_x\n",
        "\t\t\t\ty_offset = gt[img_id, 0] - mid_y\n",
        "\n",
        "\t\t\t\toffset = np.array([y_offset, x_offset])\n",
        "\t\t\t\tpatch_dists.append(offset)\n",
        "\n",
        "\t\treturn np.array(train_patches), np.array(patch_dists)\n",
        "\n",
        "\tdef shuffle(self, images, gt):\n",
        "\t\tshuffle = list(zip(images, gt))\n",
        "\t\trandom.shuffle(shuffle)\n",
        "\t\timages, gt = zip(*shuffle)\n",
        "\n",
        "\t\treturn np.array(images), np.array(gt)\n",
        "\n",
        "\tdef prepare_test_data(self):\n",
        "\t\timages_folder = '/content/drive/My Drive/drions/images'\n",
        "\t\tground_truth = '/content/drive/My Drive/anotExpert1_001.txt'\n",
        "\n",
        "\t\ttrain_images, train_output = self.load_data(images_folder, ground_truth)\n",
        "\t\ttrain_images = self.preprocess(train_images)\n",
        "\n",
        "\t\tdisc_patches = self.exctract_disc_patches(train_images, train_output)\n",
        "\t\tzero_dists = np.zeros((len(disc_patches), 2))\n",
        "\t\tprint('Disc patches: ', np.shape(disc_patches))\n",
        "\n",
        "\t\ttrain_images, train_output = self.make_patches(train_images, train_output)\n",
        "\t\tprint('Orig patches: ', np.shape(train_images))\n",
        "\n",
        "\t\ttrain_output = np.concatenate((train_output, zero_dists), axis=0)\n",
        "\t\ttrain_images = np.concatenate((train_images, disc_patches), axis=0)\n",
        "\n",
        "\t\t# randomly shuffle train array\n",
        "\t\ttrain_images, train_output = self.shuffle(train_images, train_output)\n",
        "\n",
        "\t\tprint(\"Train samples:\", np.shape(train_images))\n",
        "\t\tprint(\"Output samples:\", np.shape(train_output))\n",
        "\n",
        "\t\t# create tensors\n",
        "\t\ttrain_output = train_output[:, np.newaxis, np.newaxis, : ]\n",
        "\t\ttrain_images = train_images[..., np.newaxis]\n",
        "\n",
        "\t\treturn train_images, train_output\n",
        "\n",
        "\tdef train(self, images_folder, ground_truth):\n",
        "\n",
        "\t\tprint('train(): Images processing')\n",
        "\n",
        "\t\ttrain_images, train_output = self.load_data(images_folder, ground_truth)\n",
        "\t\ttrain_images = self.preprocess(train_images)\n",
        "\n",
        "\t\tdisc_patches = self.exctract_disc_patches(train_images, train_output)\n",
        "\t\tzero_dists = np.zeros((len(disc_patches), 2))\n",
        "\t\tprint('Disc patches: ', np.shape(disc_patches))\n",
        "\n",
        "\t\ttrain_images, train_output = self.make_patches(train_images, train_output)\n",
        "\t\tprint('Orig patches: ', np.shape(train_images))\n",
        "\n",
        "\t\ttrain_output = np.concatenate((train_output, zero_dists), axis=0)\n",
        "\t\ttrain_images = np.concatenate((train_images, disc_patches), axis=0)\n",
        "\n",
        "\t\t# randomly shuffle train array\n",
        "\t\ttrain_images, train_output = self.shuffle(train_images, train_output)\n",
        "\n",
        "\t\tprint(\"Train samples:\", np.shape(train_images))\n",
        "\t\tprint(\"Output samples:\", np.shape(train_output))\n",
        "\n",
        "\t\t# create tensors\n",
        "\t\ttrain_output = train_output[:, np.newaxis, np.newaxis, : ]\n",
        "\t\ttrain_images = train_images[..., np.newaxis]\n",
        "\n",
        "\t\ttrain_set = train_images\n",
        "\t\ttrain_y = train_output\n",
        "\t\tprint(\"train_y: \", np.shape(train_y))\n",
        "\t\tprint(\"train_set: \", np.shape(train_set))\n",
        "\n",
        "\t\ttest_images, test_output = self.prepare_test_data()\n",
        "\t\ttest_set = test_images[:130, ...]\n",
        "\t\ttest_y = test_output[:130, ...]\n",
        "\t\tprint(\"test_y: \", np.shape(test_y))\n",
        "\t\tprint(\"test_set: \", np.shape(test_set))\n",
        "\n",
        "\t\ty = tf.placeholder(\"float32\", [None, 1, 1, 2])\n",
        "\n",
        "\t\tcost = tf.reduce_mean(tf.losses.mean_squared_error(labels=y, predictions=self.output))\n",
        "\t\toptimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "\n",
        "\t\ttraining_epochs = 150\n",
        "\t\tdisplay_step = 4\n",
        "\t\tbatch_size = 130\n",
        "\t\twith self.sess as sess:           \n",
        "\t\t\tprint('train(): Training started')\n",
        "\t\t\tsess.run(tf.global_variables_initializer())\n",
        "\n",
        "\t\t\tfor epoch in range(training_epochs):\n",
        "\n",
        "\t\t\t\tavg_cost = 0.0\n",
        "\t\t\t\ttotal_batch = int(len(train_set) / batch_size) \n",
        "\t\t\t\tx_batches = np.array_split(train_set, total_batch)\n",
        "\t\t\t\ty_batches = np.array_split(train_y, total_batch)\n",
        "\n",
        "\t\t\t\tfor i in range(total_batch):\n",
        "\n",
        "\t\t\t\t\tbatch_x, batch_y = x_batches[i], y_batches[i]\n",
        "\n",
        "\t\t\t\t\t_, c = sess.run([optimizer, cost], \n",
        "\t\t\t\t\t\t\t\t\tfeed_dict={\n",
        "\t\t\t\t\t\t\t\t\t\tself.imgs: batch_x, \n",
        "\t\t\t\t\t\t\t\t\t\ty: batch_y, \n",
        "\t\t\t\t\t\t\t\t\t\tself.train_mode: True\n",
        "\t\t\t\t\t\t\t\t\t})\n",
        "\t\t\t\t\tavg_cost += c / total_batch\n",
        "\n",
        "\t\t\t\tif epoch % display_step == 0:\n",
        "\t\t\t\t\tprint(\"\\nEpoch:\", '%04d' % (epoch+1), \"\\nmse(train_set)=\", \\\n",
        "\t\t\"{:.9f}\".format(avg_cost))\n",
        "\n",
        "\t\t\t\t\tpred_y = sess.run(self.output, \n",
        "\t\t\t\t\t\t\t\t\t  feed_dict={\n",
        "\t\t\t\t\t\t\t\t\t\t   self.imgs: test_set,\n",
        "\t\t\t\t\t\t\t\t\t\t   self.train_mode: False\n",
        "\t\t\t\t\t\t\t\t\t   })\n",
        "\t\t\t\t\tmse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
        "\t\t\t\t\tprint(\"MSE(test_set): %.4f\" % sess.run(mse)) \n",
        "\n",
        "\t\t\t\t\tself.eval_test_img(sess, 90, test_set[90], test_y[90])\n",
        "\t\t\t\t\tself.eval_test_img(sess, 100, test_set[100], test_y[100])\n",
        "\t\t\t\t\tself.eval_test_img(sess, 20, test_set[20], test_y[20])\n",
        "\n",
        "\t\t\tself.saver.save(sess, './model')\n",
        "\n",
        "\tdef fine_tune(self, images_folder, ground_truth):\n",
        "\t\t\"\"\" Fine tuning with patches containing disc patches (400),\n",
        "\t\t    and with normal patches (1000). This helps the model to\n",
        "\t\t    converge and stay on the position of otpic disc, if found.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\ttrain_images, train_output = self.load_data(images_folder, ground_truth)\n",
        "\t\ttrain_images = self.preprocess(train_images)\n",
        "\n",
        "\t\tdisc_patches = self.exctract_disc_patches(train_images, train_output)\n",
        "\t\tzero_dists = np.zeros((len(disc_patches), 2))\n",
        "\t\tprint('Disc patches: ', np.shape(disc_patches))\n",
        "\n",
        "\t\ttrain_images, train_output = self.make_patches(train_images, train_output)\n",
        "\t\tprint('Orig patches: ', np.shape(train_images))\t\n",
        "\n",
        "\t\ttrain_images, train_output = self.shuffle(train_images, train_output)\n",
        "\n",
        "\t\tprint(\"Train samples:\", np.shape(train_images))\n",
        "\t\tprint(\"Output samples:\", np.shape(train_output))\n",
        "\n",
        "\t\ttrain_images = train_images[:1000, ...]\n",
        "\t\ttrain_output = train_output[:1000, ...]\n",
        "\n",
        "\t\ttrain_output = np.concatenate((train_output, zero_dists), axis=0)\n",
        "\t\ttrain_images = np.concatenate((train_images, disc_patches), axis=0)\n",
        "\n",
        "\t\ttrain_images, train_output = self.shuffle(train_images, train_output)\n",
        "\n",
        "\t\t# create tensors\n",
        "\t\ttrain_y = train_output[:, np.newaxis, np.newaxis, : ]\n",
        "\t\ttrain_set = train_images[..., np.newaxis]\n",
        "\n",
        "\t\tprint(\"train_y: \", np.shape(train_y))\n",
        "\t\tprint(\"train_set: \", np.shape(train_set))\n",
        "\n",
        "\t\ty = tf.placeholder(\"float32\", [None, 1, 1, 2])\n",
        "\n",
        "\t\tcost = tf.reduce_mean(tf.losses.mean_squared_error(labels=y, predictions=self.output))\n",
        "\t\toptimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "\n",
        "\t\ttraining_epochs = 50\n",
        "\t\tdisplay_step = 4\n",
        "\t\tbatch_size = 130\n",
        "\n",
        "\t\tprint('Starting session')\n",
        "\t\twith self.sess as sess:           \n",
        "\t\t\tsess.run(tf.global_variables_initializer())\n",
        "\t\t\tprint('train(): Training started')\n",
        "\t\t\tself.saver.restore(sess, './model')\n",
        "\t\t\tprint('Model restored')\n",
        "\n",
        "\t\t\tfor epoch in range(training_epochs):\n",
        "\n",
        "\t\t\t\tavg_cost = 0.0\n",
        "\t\t\t\ttotal_batch = int(len(train_set) / batch_size) \n",
        "\n",
        "\t\t\t\tx_batches = np.array_split(train_set, total_batch)\n",
        "\t\t\t\ty_batches = np.array_split(train_y, total_batch)\n",
        "\n",
        "\t\t\t\tfor i in range(total_batch):\n",
        "\n",
        "\t\t\t\t\tbatch_x, batch_y = x_batches[i], y_batches[i]\n",
        "\n",
        "\t\t\t\t\t_, c = sess.run([optimizer, cost], \n",
        "\t\t\t\t\t\t\t\t\tfeed_dict={\n",
        "\t\t\t\t\t\t\t\t\t\tself.imgs: batch_x, \n",
        "\t\t\t\t\t\t\t\t\t\ty: batch_y, \n",
        "\t\t\t\t\t\t\t\t\t\tself.train_mode: True\n",
        "\t\t\t\t\t\t\t\t\t})\n",
        "\t\t\t\t\tavg_cost += c / total_batch\n",
        "\n",
        "\t\t\t\tif epoch % display_step == 0:\n",
        "\t\t\t\t\tprint(\"\\nEpoch:\", '%04d' % (epoch+1), \"\\nmse(train_set)=\", \\\n",
        "\t\t\"{:.9f}\".format(avg_cost))\n",
        "\n",
        "\t\t\tself.saver.save(sess, './model_tuned')\n",
        "\n",
        "\tdef detect(self, image_file):\n",
        "\n",
        "\t\timage_orig = cv2.imread(image_file, 0)\n",
        "\t\timage_orig = resize(image_orig, (201, 250))\n",
        "\n",
        "\t\t\"\"\" Preprocessing \"\"\"\n",
        "\t\tclahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(40,40))\n",
        "\t\timg = clahe.apply(image_orig)\n",
        "\n",
        "\t\timg = cv2.bilateralFilter(img, -1, 20, 20)\n",
        "\n",
        "\t\tintensities = medfilt(img, (21, 21))\n",
        "\t\tintensities = intensities.astype(np.float32)\n",
        "\t\tintensities_smoothed = cv2.bilateralFilter(intensities, -1, 70, 13)\n",
        "\t\twidth, height = img.shape\n",
        "\t\timg[0:width, 0:height] = img[0:width, 0:height] + (90) - intensities_smoothed[0:width, 0:height]\n",
        "\t\tidx = img[:] > 210\n",
        "\t\timg[idx] = 18\n",
        "\n",
        "\t\tclahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(1,1))\n",
        "\t\timg = clahe.apply(img)\n",
        "\n",
        "\t\timg_h, img_w = img.shape\n",
        "\t\tpatch_width = 42\n",
        "\t\tpatch_height = 45\n",
        "\t\tstart_idx = 60\n",
        "\t\tstart_idy = 40\n",
        "\n",
        "\t\tinput_img = img[start_idy:start_idy+patch_height, start_idx:start_idx+patch_width].copy()\n",
        "\t\tinput_img = input_img[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "\t\titers = 20\n",
        "\t\twith self.sess as sess:\n",
        "\t\t\tself.saver.restore(sess, './model_tuned')\n",
        "\t\t\tprint('After displaying the image, press any key to continue. (', iters, ' steps)')\n",
        "\t\t\tfor i in range(iters):\t\t\t\t\n",
        "\t\t\t\tprint('Iter: ', i, '/', iters-1)\n",
        "\n",
        "\t\t\t\tpred = sess.run(self.output, \n",
        "\t\t\t\t\t            feed_dict={\n",
        "\t\t\t\t\t\t\t\t\t      self.imgs: input_img, \n",
        "\t\t\t\t\t\t\t\t\t      self.train_mode: False\n",
        "\t\t\t\t\t\t\t\t          })\n",
        "\n",
        "\t\t\t\tstart_idx = start_idx + int(pred[0,0,0,1])\n",
        "\t\t\t\tstart_idy = start_idy + int(pred[0,0,0,0])\n",
        "\t\t\t\tif start_idx < 0:\n",
        "\t\t\t\t\tstart_idx = 0\n",
        "\t\t\t\tif start_idy < 0:\n",
        "\t\t\t\t\tstart_idy = 0\n",
        "\t\t\t\tif (start_idx + patch_width) >= img_w:\n",
        "\t\t\t\t\tstart_idx = img_w - patch_width\n",
        "\t\t\t\tif (start_idy + patch_height) >= img_h:\n",
        "\t\t\t\t\tstart_idy = img_h - patch_height\n",
        "\t\t\t\tend_idx = start_idx + patch_width\n",
        "\t\t\t\tend_idy = start_idy + patch_height\n",
        "\n",
        "\t\t\t\tinput_img = img[start_idy:end_idy, start_idx:end_idx].copy()\n",
        "\t\t\t\tinput_img = input_img[np.newaxis, ..., np.newaxis]\n",
        "\t\t\t\t\n",
        "\t\t\t\timg_show = image_orig.copy()\n",
        "\t\t\t\tcv2.imshow('detection', cv2.rectangle(img_show,(start_idx,start_idy),(end_idx,end_idy),(0,255,0),1))\n",
        "\t\t\t\tcv2.waitKey(0)\n",
        "\n",
        "\tdef eval_model(self, images_folder, gt_file):\n",
        "\t\timages = []\n",
        "\t\tfor filename in os.listdir(images_folder):\n",
        "\t\t\timg = cv2.imread(os.path.join(images_folder, filename), 0)\n",
        "\t\t\tif img is not None:\n",
        "\t\t\t\timages.append(imresize(img, (201, 250)))\t\n",
        "\t\ttrain_images = np.array(images)\n",
        "\n",
        "\t\ttrain_images = self.preprocess(train_images)\n",
        "\t\t\t\t\t\t\n",
        "\t\timg_h, img_w = images[0].shape\n",
        "\t\tprint(img_h, img_w)\n",
        "\n",
        "\t\twith self.sess as sess:\n",
        "\t\t\tself.saver.restore(sess, './model_tuned')\n",
        "\t\t\toutput = []\n",
        "\t\t\tpatch_width = 42\n",
        "\t\t\tpatch_height = 45\n",
        "\n",
        "\t\t\timages_cnt = len(train_images)\n",
        "\t\t\tfor img in train_images:\n",
        "\t\t\t\t\n",
        "\t\t\t\tstart_idx = 60\n",
        "\t\t\t\tstart_idy = 40\n",
        "\t\t\t\tinput_img = img[start_idy:start_idy+patch_height, start_idx:start_idx+patch_width]\n",
        "\t\t\t\tinput_img = input_img[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "\t\t\t\titers = 15\n",
        "\t\t\t\tfor i in range(iters):\t\t\t\t\n",
        "\t\t\t\t\tpred = sess.run(self.output, \n",
        "\t\t\t\t\t\t            feed_dict={\n",
        "\t\t\t\t\t\t\t\t\t\t      self.imgs: input_img, \n",
        "\t\t\t\t\t\t\t\t\t\t      self.train_mode: False\n",
        "\t\t\t\t\t\t\t\t\t          })\n",
        "\n",
        "\t\t\t\t\tstart_idx = start_idx + int(pred[0,0,0,1])\n",
        "\t\t\t\t\tstart_idy = start_idy + int(pred[0,0,0,0])\n",
        "\t\t\t\t\tif start_idx < 0:\n",
        "\t\t\t\t\t\tstart_idx = 0\n",
        "\t\t\t\t\tif start_idy < 0:\n",
        "\t\t\t\t\t\tstart_idy = 0\n",
        "\t\t\t\t\tif (start_idx + patch_width) >= img_w:\n",
        "\t\t\t\t\t\tstart_idx = img_w - patch_width\n",
        "\t\t\t\t\tif (start_idy + patch_height) >= img_h:\n",
        "\t\t\t\t\t\tstart_idy = img_h - patch_height\n",
        "\t\t\t\t\tend_idx = start_idx + patch_width\n",
        "\t\t\t\t\tend_idy = start_idy + patch_height\n",
        "\n",
        "\t\t\t\t\tinput_img = img[start_idy:end_idy, start_idx:end_idx]\n",
        "\t\t\t\t\tinput_img = input_img[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "\t\t\t\tx_final = start_idx + 21\n",
        "\t\t\t\ty_final = start_idy + 23\n",
        "\n",
        "\t\t\t\toutput.append(np.array([y_final, x_final]))\n",
        "\n",
        "\t\t\toutput = np.array(output)\n",
        "\n",
        "\t\t\tground_truth = np.loadtxt(gt_file)\n",
        "\n",
        "\t\t\ttotal = 0\n",
        "\t\t\tradius_10 = 0\n",
        "\t\t\tradius_20 = 0\n",
        "\t\t\tfor i, x in enumerate(ground_truth):\n",
        "\t\t\t\td = math.sqrt((x[0]-output[i,0])**2 + ((x[1]-output[i,1])**2))\n",
        "\t\t\t\ttotal += d\n",
        "\t\t\t\tif d < 10:\n",
        "\t\t\t\t\tradius_10 += 1 \n",
        "\t\t\t\tif d < 20:\n",
        "\t\t\t\t\tradius_20 += 1\n",
        "\n",
        "\t\t\ttotal = total / images_cnt\n",
        "\t\t\tprint('Avg. distance from gt: ', total)\n",
        "\t\t\tprint('Detections with distance under 10: ', radius_10)\n",
        "\t\t\tprint('Detections with distance under 20: ', radius_20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M10jTYAKtN6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "74a6f73c-3ffd-4e25-f55a-19fe4f5b8762"
      },
      "source": [
        "sess = tf.Session()\n",
        "detector = optic_disc_detector(sess)\n",
        "detector.train(images_folder,ground_truth)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0810 14:43:22.782707 139990842763136 deprecation.py:323] From <ipython-input-6-27fe158d6e85>:38: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "convlayers(): Initializing layers\n",
            "output:  (?, 1, 1, 2)\n",
            "train(): Images processing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:252: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:254: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-96c6a2fb542a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptic_disc_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-27fe158d6e85>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, images_folder, ground_truth)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mdisc_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexctract_disc_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-27fe158d6e85>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m    186\u001b[0m                         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilateralFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                         \u001b[0mintensities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m                         \u001b[0mintensities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintensities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0mintensities_smoothed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilateralFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintensities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36mmedfilt\u001b[0;34m(volume, kernel_size)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mnumels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumels\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order_filterND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeNaJQEa6Wwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_file='/content/drive/My Drive/origa-light/glaucoma'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OolfkCT6-z0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "9a9669b7-1955-4436-9fdf-c6031e404e7c"
      },
      "source": [
        "sess = tf.Session()\n",
        "detector = optic_disc_detector(sess)\n",
        "detector.detect(images_folder)\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0810 15:10:25.914231 140386704906112 deprecation.py:323] From <ipython-input-4-cdfec27c4c0c>:38: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "convlayers(): Initializing layers\n",
            "output:  (?, 1, 1, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2c4d7bf41c9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptic_disc_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cdfec27c4c0c>\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, image_file)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0mimage_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0mimage_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;34m\"\"\" Preprocessing \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0moutput_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_ndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# append dimensions to input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}