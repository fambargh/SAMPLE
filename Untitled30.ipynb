{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled30.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fambargh/SAMPLE/blob/master/Untitled30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v78cH6slrFnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6ea51af3-d5f1-4cb1-f94d-806026dafefb"
      },
      "source": [
        "pip install Pillow\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiYofFRkrQX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "923421f0-e610-4674-ec72-e3184f723c2b"
      },
      "source": [
        "pip install scipy==1.1.0\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6zUrWHwraBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import UpSampling2D, Conv2D, Activation, BatchNormalization, Reshape, Dense, Input, LeakyReLU, Dropout, Flatten, ZeroPadding2D\n",
        "from keras import optimizers \n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "from ast import literal_eval\n",
        "\n",
        "from scipy.misc import imsave,imresize\n",
        "from keras import backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1pVPctX08kD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bcf19b3-dc4d-4c5f-e61d-9015891d7e8f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Niwzly-Z08hn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e898d4a8-a04e-4c45-e130-b85fcf8eccf9"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "imagepath='/content/drive/My Drive/riga1'\n",
        "#epochs=10\n",
        "#image_path= image.load_img(imagepath)\n",
        "#img = Image.open(fd_img)\n",
        "#img = resizeimage.resize_thumbnail(img, [200, 200])\n",
        "#img.save('test-image-thumbnail.jpeg', img.format)\n",
        "#fd_img.close()\n",
        "#resized = cv2.resize(img, (width, height), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "#resized = cv2.resize(fd_img, (128,128))\n",
        "print(image_path.size)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2376, 1584)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kriYNOw08a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_directory='/content/drive/My Drive/rigam'\n",
        "img_size=[2376, 1584]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMvrqG6R08Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_path='/content/drive/My Drive/rigam'\n",
        "generator_path='/content/drive/My Drive/rigam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSvnqJnmrmL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGAN:\n",
        "    def __init__(self, output_directory, img_size):\n",
        "        self.img_size = img_size\n",
        "        self.upsample_layers = 2\n",
        "        self.starting_filters = 256\n",
        "        self.kernel_size = 5\n",
        "        self.channels = 3\n",
        "        #self.discriminator_path = discriminator_path\n",
        "        #self.generator_path = generator_path\n",
        "        self.output_directory = output_directory\n",
        "\n",
        "    def build_generator(self):\n",
        "        noise_shape = (100,)\n",
        "\n",
        "        # This block of code can be a little daunting, but essentially it automatically calculates the required starting\n",
        "        # array size that will be correctly upscaled to our desired image size.\n",
        "        #\n",
        "        # We have 5 Upsample2D layers which each double the images width and height, so we can determine the starting\n",
        "        # x size by taking (x / 2^upsample_count) So for our target image size, 256x192, we do the following:\n",
        "        # x = (192 / 2^5), y = (256 / 2^5) [x and y are reversed within the model]\n",
        "        # We also need a 3rd dimension which is chosen relatively arbitrarily, in this case it's 64.\n",
        "        model = Sequential()\n",
        "        model.add(\n",
        "            Dense(self.starting_filters * (self.img_size[0] // (2 ** self.upsample_layers))  *  (self.img_size[1] // (2 ** self.upsample_layers)),\n",
        "                  activation=\"relu\", input_shape=noise_shape))\n",
        "        model.add(Reshape(((self.img_size[0] // (2 ** self.upsample_layers)),\n",
        "                           (self.img_size[1] // (2 ** self.upsample_layers)),\n",
        "                           self.starting_filters)))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())  # 6x8 -> 12x16\n",
        "        model.add(Conv2D(512, kernel_size=self.kernel_size,strides=1, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())  # 12x16 -> 24x32\n",
        "        model.add(Conv2D(256, kernel_size=self.kernel_size,strides=1, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Conv2D(128, kernel_size=self.kernel_size,strides=1, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Conv2D(self.channels, kernel_size=self.kernel_size,strides=1, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=noise_shape)\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(128, kernel_size=self.kernel_size, strides=2, input_shape=img_shape, padding=\"same\"))  # 192x256 -> 96x128\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, kernel_size=self.kernel_size, strides=2, padding=\"same\"))  # 96x128 -> 48x64\n",
        "        #model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.4))\n",
        "        \n",
        "        model.add(Conv2D(512, kernel_size=self.kernel_size, strides=1, padding=\"same\"))  # 48x64 -> 24x32\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def build_gan(self):\n",
        "        #optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # See if the specified model paths exist, if they don't then we start training new models\n",
        "\n",
        "        #if os.path.exists(self.discriminator_path) and os.path.exists(self.generator_path):\n",
        "            #self.discriminator = load_model(self.discriminator_path)\n",
        "            #self.generator = load_model(self.generator_path)\n",
        "            #print(\"Loaded models...\")\n",
        "        #else:\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=optimizers.SGD(lr=0.01),\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "        self.generator = self.build_generator()\n",
        "        self.generator.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(0.0002, 0.5))\n",
        "\n",
        "        # These next few lines setup the training for the GAN model\n",
        "        z = Input(shape=(100,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        valid = self.discriminator(img)\n",
        "\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(0.0002, 0.5))\n",
        "\n",
        "    def load_imgs(self, image_path):\n",
        "        X_train = []\n",
        "        for i in glob.glob(image_path):\n",
        "            img = Image.open(i)\n",
        "            img = np.asarray(img)\n",
        "            X_train.append(img)\n",
        "        return np.asarray(X_train)\n",
        "\n",
        "    def train(self, epochs, image_path, batch_size=32, save_interval=50):\n",
        "        self.build_gan()\n",
        "        X_train = self.load_imgs(image_path)\n",
        "        print(\"Training Data Shape: \", X_train.shape)\n",
        "\n",
        "        # Rescale images from -1 to 1\n",
        "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "        half_batch = batch_size // 2\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "\n",
        "            # Train Generator\n",
        "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "\n",
        "\n",
        "            # Train Discriminator\n",
        "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            # Sample noise and generate a half batch of new images\n",
        "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            # Train the discriminator (real classified as ones and generated as zeros)\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # Print progress\n",
        "            print(f\"{epoch} [D loss: {d_loss[0]} | D Accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
        "\n",
        "            # If at save interval => save generated image samples, save model files\n",
        "            if epoch % (save_interval) == 0:\n",
        "\n",
        "                self.save_imgs(epoch)\n",
        "\n",
        "                save_path = self.output_directory + \"/models\"\n",
        "                if not os.path.exists(save_path):\n",
        "                    os.makedirs(save_path)\n",
        "                self.discriminator.save(save_path + \"/discrim.h5\")\n",
        "                self.generator.save(save_path + \"/generat.h5\")\n",
        "\n",
        "    def gene_imgs(self, count):\n",
        "        # Generate images from the currently loaded model\n",
        "        noise = np.random.normal(0, 1, (count, 100))\n",
        "        return self.generator.predict(noise)\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "        r, c = 5, 5\n",
        "\n",
        "        # Generates r*c images from the model, saves them individually and as a gallery\n",
        "\n",
        "        imgs = self.gene_imgs(r*c)\n",
        "        imgs = 0.5 * imgs + 0.5\n",
        "\n",
        "        for i, img_array in enumerate(imgs):\n",
        "            path = f\"{self.output_directory}/generated_{self.img_size[0]}x{self.img_size[1]}\"\n",
        "            if not os.path.exists(path):\n",
        "                os.makedirs(path)\n",
        "            imsave(path + f\"/{epoch}_{i}.png\", img_array)\n",
        "\n",
        "        nindex, height, width, intensity = imgs.shape\n",
        "        nrows = nindex // c\n",
        "        assert nindex == nrows * c\n",
        "        # want result.shape = (height*nrows, width*ncols, intensity)\n",
        "        gallery = (imgs.reshape(nrows, c, height, width, intensity)\n",
        "                  .swapaxes(1, 2)\n",
        "                  .reshape(height * nrows, width * c, intensity))\n",
        "\n",
        "        path = f\"{self.output_directory}/gallery_generated_{self.img_size[0]}x{self.img_size[1]}\"\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        imsave(path + f\"/{epoch}.png\", gallery)\n",
        "\n",
        "    def generate_imgs(self, count, threshold, modifier):\n",
        "        self.build_gan()\n",
        "\n",
        "        # Generates (count) images from the model ensuring the discriminator scores them between the threshold values\n",
        "        # and saves them\n",
        "\n",
        "        imgs = []\n",
        "        for i in range(count):\n",
        "            score = [0]\n",
        "            while not(threshold[0] < score[0] < threshold[1]):\n",
        "                img = self.gene_imgs(1)\n",
        "                score = self.discriminator.predict(img)\n",
        "            print(\"Image found: \", score[0])\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.asarray(imgs).squeeze()\n",
        "        imgs = 0.5 * imgs + 0.5\n",
        "\n",
        "        print(imgs.shape)\n",
        "        for i, img_array in enumerate(imgs):\n",
        "            path = f\"{self.output_directory}/generated_{threshold[0]}_{threshold[1]}\"\n",
        "            if not os.path.exists(path):\n",
        "                os.makedirs(path)\n",
        "            imsave(path + f\"/{modifier}_{i}.png\", img_array)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoXThZmVy88W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ee50043-7b29-4b5e-a20b-b38ff1c8009f"
      },
      "source": [
        "s=DCGAN(output_directory, img_size)\n",
        "s.train(epochs, image_path, batch_size=32, save_interval=50)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_29 (Conv2D)           (None, 1188, 792, 128)    9728      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 1188, 792, 128)    0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1188, 792, 128)    0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 594, 396, 256)     819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 594, 396, 256)     0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 594, 396, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 594, 396, 512)     3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 594, 396, 512)     0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 594, 396, 512)     0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 120434688)         0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 120434689 \n",
            "=================================================================\n",
            "Total params: 124,541,185\n",
            "Trainable params: 124,541,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 60217344)          6081951744\n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 594, 396, 256)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 594, 396, 256)     1024      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2 (None, 1188, 792, 256)    0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1188, 792, 512)    3277312   \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 1188, 792, 512)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 1188, 792, 512)    2048      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling (None, 2376, 1584, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 2376, 1584, 256)   3277056   \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 2376, 1584, 256)   0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 2376, 1584, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 2376, 1584, 128)   819328    \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 2376, 1584, 128)   0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 2376, 1584, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 2376, 1584, 3)     9603      \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 2376, 1584, 3)     0         \n",
            "=================================================================\n",
            "Total params: 6,089,339,651\n",
            "Trainable params: 6,089,337,347\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-5c9868083a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-d4a1999f3653>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, image_path, batch_size, save_interval)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Data Shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-d4a1999f3653>\u001b[0m in \u001b[0;36mload_imgs\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_iglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"Split a pathname.  Returns tuple \"(head, tail)\" where \"tail\" is\n\u001b[1;32m    106\u001b[0m     everything after the final slash.  Either part may be empty.\"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not JpegImageFile"
          ]
        }
      ]
    }
  ]
}