{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fambargh/SAMPLE/blob/master/Untitled31-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXY-HJXjJQ4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byj0UKdUN73F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import UpSampling2D, Conv2D, Activation, BatchNormalization, Reshape, Dense, Input, LeakyReLU, Dropout, Flatten\n",
        "from keras import optimizers \n",
        "import numpy as np\n",
        "from keras import layers\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "from ast import literal_eval\n",
        "\n",
        "#from scipy.misc import imsave,imresize\n",
        "from keras import backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szuzu4wMJT00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfa51e82-5b8a-4491-d1d9-ef329ddd41ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soGwvGQ2JT3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "577d86dd-e6e8-45cd-b78a-6adc8dc4b0e1"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_path='/content/drive/My Drive/rigam'\n",
        "#r=os.path.join(image_path,'sanas')\n",
        "#os.mkdir(image_path)\n",
        "t_d=ImageDataGenerator(rescale=1./255)\n",
        "t_g=t_d.flow_from_directory(image_path,target_size=(128,128),batch_size=20)\n",
        "#print(image_path.size)\n",
        "#im=image.load_img(image_path)\n",
        "#print(im.format)\n",
        "#from keras import cifar10\n",
        "#c=cifar10.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 33 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP-kfQzgJdGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_directory='/content/drive/My Drive/rigam'\n",
        "img_size=[128,128]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGOGgbkshv1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Use PrettyTensor to simplify Neural Network construction.\n",
        "#import prettytensor as pt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GkUM5bPJdPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_path='/content/drive/My Drive/rigam'\n",
        "generator_path='/content/drive/My Drive/rigam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_nqkZ_MJpTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "79b51305-66d7-462a-a15e-3f064eeeaf67"
      },
      "source": [
        "noise_shape = (100,)\n",
        "kernel_size=5\n",
        "channels=3\n",
        "        # This block of code can be a little daunting, but essentially it automatically calculates the required starting\n",
        "        # array size that will be correctly upscaled to our desired image size.\n",
        "        #\n",
        "        # We have 5 Upsample2D layers which each double the images width and height, so we can determine the starting\n",
        "        # x size by taking (x / 2^upsample_count) So for our target image size, 256x192, we do the following:\n",
        "        # x = (192 / 2^5), y = (256 / 2^5) [x and y are reversed within the model]\n",
        "        # We also need a 3rd dimension which is chosen relatively arbitrarily, in this case it's 64.\n",
        "generator_input=Input(shape=noise_shape)\n",
        "x=layers.Dense(128*32*32)(generator_input)\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.Reshape((32,32,128))(x)\n",
        "x=layers.BatchNormalization(momentum=0.8)(x)\n",
        "x=layers.UpSampling2D()(x)\n",
        "x=layers.Conv2D(512, kernel_size=kernel_size,strides=1, padding=\"same\")(x)\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(momentum=0.8)(x)\n",
        "x=layers.UpSampling2D()(x)\n",
        "x=layers.Conv2D(256, kernel_size=kernel_size,strides=1, padding=\"same\")(x)\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(momentum=0.8)(x)\n",
        "x=layers.Conv2D(128, kernel_size=kernel_size,strides=1, padding=\"same\")(x)\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(momentum=0.8)(x)\n",
        "x=layers.Conv2D(channels, kernel_size=kernel_size,strides=1,activation='tanh', padding=\"same\")(x)\n",
        "generator=Model(generator_input,x)\n",
        "generator.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0821 10:42:06.547492 139736253269888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0821 10:42:06.599857 139736253269888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0821 10:42:06.608029 139736253269888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0821 10:42:06.649646 139736253269888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0821 10:42:06.650955 139736253269888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0821 10:42:09.963110 139736253269888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0821 10:42:10.057076 139736253269888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 131072)            13238272  \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 512)       1638912   \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 64, 64, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 512)       2048      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 128, 128, 512)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 256)     3277056   \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 128, 128, 256)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128, 128, 256)     1024      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 128, 128, 128)     819328    \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 128, 128, 3)       9603      \n",
            "=================================================================\n",
            "Total params: 18,987,267\n",
            "Trainable params: 18,985,219\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoto5eR1JpaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "03087e9b-873d-48a2-fbc1-08983e7ddaab"
      },
      "source": [
        "discriminator_input = Input(shape=(img_size[0], img_size[1], channels))\n",
        "x=layers.Conv2D(128, kernel_size=kernel_size, strides=2, padding=\"same\")(discriminator_input)\n",
        "x=layers.LeakyReLU(alpha=0.2)(x)\n",
        "x=layers.Dropout(0.4)(x)\n",
        "x=layers.Conv2D(256, kernel_size=kernel_size, strides=2, padding=\"same\")(x)\n",
        "x=layers.LeakyReLU(alpha=0.2)(x)\n",
        "x=layers.Dropout(0.4)(x)\n",
        "x=layers.Conv2D(512, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n",
        "x=layers.LeakyReLU(alpha=0.2)(x)\n",
        "x=layers.Dropout(0.4)(x)\n",
        "x=layers.Flatten()(x)\n",
        "x=layers.Dense(1, activation='sigmoid')(x)\n",
        "discriminator=Model(discriminator_input,x)\n",
        "discriminator.summary()\n",
        "        "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0821 10:42:18.525095 139736253269888 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 64, 64, 128)       9728      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 512)       3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32, 32, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 524288)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 524289    \n",
            "=================================================================\n",
            "Total params: 4,630,785\n",
            "Trainable params: 4,630,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pMIyKQJJpkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "250ae14e-8b98-499e-c5b9-c14f936cdc30"
      },
      "source": [
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=optimizers.SGD(lr=0.01),\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "generator.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(0.0002, 0.5))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0821 10:42:23.831871 139736253269888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0821 10:42:23.842375 139736253269888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0vnaZeTJpmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_trainable=False\n",
        "gan_input=Input(shape=noise_shape)\n",
        "gan_output=discriminator(generator(gan_input))\n",
        "gan=Model(gan_input,gan_output)\n",
        "gan.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(0.0002, 0.5))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpUPUqthWPrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "x_train=t_g\n",
        "#x_train=image.load_img(image_path)\n",
        "#x_train=x_train.reshape((x_train.shape[0],)+(32,32,128)).astype('float32')/255.\n",
        "iterations=1\n",
        "batch_size=20\n",
        "save_dir=output_directory\n",
        "start=0\n",
        "for step in range(iterations):\n",
        "  r_l_v=np.random.normal(size=(batch_size,100))\n",
        "  \n",
        "  generated_images=generator.predict(r_l_v)\n",
        "  \n",
        "  stop=start+batch_size\n",
        "  real_images=x_train\n",
        "  combined_images=np.concatenate([generated_images,real_images])\n",
        "\n",
        "  labels = np.concatenate([np.ones((batch_size, 1)),np.zeros((batch_size, 1))])\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size,100))\n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "  a_loss = gan.train_on_batch(random_latent_vectors,misleading_targets)\n",
        "  start += batch_size\n",
        "  if start > len(x_train) - batch_size:\n",
        "    start = 0\n",
        "    \n",
        "  if step % 100 == 0:\n",
        "    gan.save_weights('gan.h5')\n",
        "    print('discriminator loss:', d_loss)\n",
        "    print('adversarial loss:', a_loss)\n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir,'generated_frog' + str(step) + '.png'))\n",
        "    img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir,'real_frog' + str(step) + '.png'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}