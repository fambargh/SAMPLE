{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fambargh/SAMPLE/blob/master/Untitled31j.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXY-HJXjJQ4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byj0UKdUN73F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import UpSampling2D, Conv2D, Activation, BatchNormalization, Reshape, Dense, Input, LeakyReLU, Dropout, Flatten\n",
        "from keras import optimizers \n",
        "import numpy as np\n",
        "from keras import layers\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "from ast import literal_eval\n",
        "\n",
        "#from scipy.misc import imsave,imresize\n",
        "from keras import backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szuzu4wMJT00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "fb070162-8a67-4978-a191-18a9bc68e1dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soGwvGQ2JT3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f80c187d-bdcc-4243-ee47-4e1e2384b3a1"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_path='/content/drive/My Drive/origa-light'\n",
        "#r=os.path.join(image_path,'sanas')\n",
        "#os.mkdir(image_path)\n",
        "t_d=ImageDataGenerator(rescale=1./255)\n",
        "t_g=t_d.flow_from_directory(image_path,target_size=(128,128),batch_size=20)\n",
        "#print(image_path.size)\n",
        "#im=image.load_img(image_path)\n",
        "#print(im.format)\n",
        "#from keras import cifar10\n",
        "#c=cifar10.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 650 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP-kfQzgJdGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_directory='/content/drive/My Drive/rigam'\n",
        "img_size=[128,128]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGOGgbkshv1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Use PrettyTensor to simplify Neural Network construction.\n",
        "#import prettytensor as pt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBpz6GbeiQcM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e0a0d057-8616-40c7-f09c-fa061f6d2890"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvbEWZTlincu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "92c6a55e-dd26-4e22-e55b-ee546d23e641"
      },
      "source": [
        "print(x_train.format)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-ce8b7a244ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'format'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GkUM5bPJdPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_path='/content/drive/My Drive/rigam'\n",
        "generator_path='/content/drive/My Drive/rigam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_nqkZ_MJpTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "2465c6f5-1674-4969-bf1f-3163a720e339"
      },
      "source": [
        "noise_shape = (100,)\n",
        "kernel_size=5\n",
        "channels=3\n",
        "        # This block of code can be a little daunting, but essentially it automatically calculates the required starting\n",
        "        # array size that will be correctly upscaled to our desired image size.\n",
        "        #\n",
        "        # We have 5 Upsample2D layers which each double the images width and height, so we can determine the starting\n",
        "        # x size by taking (x / 2^upsample_count) So for our target image size, 256x192, we do the following:\n",
        "        # x = (192 / 2^5), y = (256 / 2^5) [x and y are reversed within the model]\n",
        "        # We also need a 3rd dimension which is chosen relatively arbitrarily, in this case it's 64.\n",
        "generator_input=Input(shape=noise_shape)\n",
        "x=layers.Dense(128*32*32)(generator_input)\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.Reshape((32,32,128))(x)\n",
        "x=layers.BatchNormalization(momentum=0.8)(x)\n",
        "x=layers.UpSampling2D()(x)\n",
        "x=layers.Conv2D(512, kernel_size=kernel_size,strides=1, padding=\"same\")(x)\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(momentum=0.8)(x)\n",
        "x=layers.UpSampling2D()(x)\n",
        "x=layers.Conv2D(256, kernel_size=kernel_size,strides=1, padding=\"same\")(x)\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(momentum=0.8)(x)\n",
        "x=layers.Conv2D(128, kernel_size=kernel_size,strides=1, padding=\"same\")(x)\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(momentum=0.8)(x)\n",
        "x=layers.Conv2D(channels, kernel_size=kernel_size,strides=1,activation='tanh', padding=\"same\")(x)\n",
        "generator=Model(generator_input,x)\n",
        "generator.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0820 17:13:21.264331 139986494793600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0820 17:13:21.321936 139986494793600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0820 17:13:21.332800 139986494793600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0820 17:13:21.376102 139986494793600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0820 17:13:21.377680 139986494793600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0820 17:13:24.953129 139986494793600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0820 17:13:25.036283 139986494793600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 131072)            13238272  \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 512)       1638912   \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 64, 64, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 512)       2048      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 128, 128, 512)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 256)     3277056   \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 128, 128, 256)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128, 128, 256)     1024      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 128, 128, 128)     819328    \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 128, 128, 3)       9603      \n",
            "=================================================================\n",
            "Total params: 18,987,267\n",
            "Trainable params: 18,985,219\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoto5eR1JpaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "13f6bb22-fb38-4a0a-d710-6fb3fd4fbc16"
      },
      "source": [
        "discriminator_input = Input(shape=(img_size[0], img_size[1], channels))\n",
        "x=layers.Conv2D(128, kernel_size=kernel_size, strides=2, padding=\"same\")(discriminator_input)\n",
        "x=layers.LeakyReLU(alpha=0.2)(x)\n",
        "x=layers.Dropout(0.4)(x)\n",
        "x=layers.Conv2D(256, kernel_size=kernel_size, strides=2, padding=\"same\")(x)\n",
        "x=layers.LeakyReLU(alpha=0.2)(x)\n",
        "x=layers.Dropout(0.4)(x)\n",
        "x=layers.Conv2D(512, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n",
        "x=layers.LeakyReLU(alpha=0.2)(x)\n",
        "x=layers.Dropout(0.4)(x)\n",
        "x=layers.Flatten()(x)\n",
        "x=layers.Dense(1, activation='sigmoid')(x)\n",
        "discriminator=Model(discriminator_input,x)\n",
        "discriminator.summary()\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0820 17:13:32.070266 139986494793600 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 64, 64, 128)       9728      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 512)       3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32, 32, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 524288)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 524289    \n",
            "=================================================================\n",
            "Total params: 4,630,785\n",
            "Trainable params: 4,630,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pMIyKQJJpkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "536034ab-6568-41a7-fd5b-14407280f7bf"
      },
      "source": [
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=optimizers.SGD(lr=0.01),\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "generator.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(0.0002, 0.5))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0820 17:13:39.070852 139986494793600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0820 17:13:39.084459 139986494793600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0vnaZeTJpmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_trainable=False\n",
        "gan_input=Input(shape=noise_shape)\n",
        "gan_output=discriminator(generator(gan_input))\n",
        "gan=Model(gan_input,gan_output)\n",
        "gan.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(0.0002, 0.5))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpUPUqthWPrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "x_train=t_g\n",
        "#x_train=image.load_img(image_path)\n",
        "#x_train=x_train.reshape((x_train.shape[0],)+(32,32,128)).astype('float32')/255.\n",
        "iterations=10\n",
        "batch_size=20\n",
        "save_dir=output_directory\n",
        "start=0\n",
        "for step in range(iterations):\n",
        "  r_l_v=np.random.normal(size=(batch_size,100))\n",
        "  \n",
        "  generated_images=generator.predict(r_l_v)\n",
        "  \n",
        "  stop=start+batch_size\n",
        "  real_images=x_train\n",
        "  combined_images=np.concatenate([generated_images,real_images])\n",
        "\n",
        "  labels = np.concatenate([np.ones((batch_size, 1)),np.zeros((batch_size, 1))])\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size,100))\n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "  a_loss = gan.train_on_batch(random_latent_vectors,misleading_targets)\n",
        "  start += batch_size\n",
        "  if start > len(x_train) - batch_size:\n",
        "    start = 0\n",
        "    \n",
        "  if step % 100 == 0:\n",
        "    gan.save_weights('gan.h5')\n",
        "    print('discriminator loss:', d_loss)\n",
        "    print('adversarial loss:', a_loss)\n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir,'generated_frog' + str(step) + '.png'))\n",
        "    img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir,'real_frog' + str(step) + '.png'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}