{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fambargh/SAMPLE/blob/master/fine_tune2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umQSR94f1x4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "75c858e0-b25e-4db7-8c24-ce0c78dbc8b0"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Uu9LhFJQoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip fine-tuning-keras.zip\n",
        "#!cd fine-tuning-keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAnxlUqFKasN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir /content/fine-tuning-keras/Food-11\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1YzA6CkcyQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/fine-tuning-keras/Food-11\n",
        "!unzip classification1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPU0GLaX7gM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f865fbd9-a530-4afe-bed7-680a0727c09e"
      },
      "source": [
        "%cd /content/fine-tuning-keras/dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fine-tuning-keras/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuQZt3MY7fvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm -rf train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kn2bcYZg_4Q",
        "colab_type": "code",
        "outputId": "33d26773-3f2a-4969-eb25-6e57ca6325b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd /content/fine-tuning-keras"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fine-tuning-keras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wid-AZ6WeCY0",
        "colab_type": "code",
        "outputId": "06dc6692-1272-4b83-e095-046024905d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "! python build_dataset.py "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] processing 'train split'...\n",
            "[INFO] processing 'test split'...\n",
            "[INFO] processing 'valid split'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-tapDzveMCI",
        "colab_type": "code",
        "outputId": "6b01e91b-a65d-483a-9ef1-3658ae504bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ls /content/fine-tuning-keras/dataset/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0eo6lJ5jNiT",
        "colab_type": "code",
        "outputId": "1c47659f-d3a9-4013-e864-b943c7c8d7d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ls  /content/fine-tuning-keras/dataset/train/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m0\u001b[0m/  \u001b[01;34m1\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NufKbjQujNf6",
        "colab_type": "code",
        "outputId": "66cd43ff-6aaa-45ac-9abf-322c006793ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "ls -l /content/fine-tuning-keras/dataset/train/0/*.png | head -n 5"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 23482 Dec 20 23:46 /content/fine-tuning-keras/dataset/train/0/0.drishtiGS_041.png\n",
            "-rw-r--r-- 1 root root 24054 Dec 20 23:46 /content/fine-tuning-keras/dataset/train/0/0.drishtiGS_042.png\n",
            "-rw-r--r-- 1 root root 22324 Dec 20 23:46 /content/fine-tuning-keras/dataset/train/0/0.drishtiGS_046.png\n",
            "-rw-r--r-- 1 root root 23259 Dec 20 23:46 /content/fine-tuning-keras/dataset/train/0/0.drishtiGS_047.png\n",
            "-rw-r--r-- 1 root root 20738 Dec 20 23:46 /content/fine-tuning-keras/dataset/train/0/0.drishtiGS_057.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttPXP3-yjNdP",
        "colab_type": "code",
        "outputId": "bd2f3c8d-71c9-44f2-a4e9-4fe03e426b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! python train.py"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Found 182 images belonging to 2 classes.\n",
            "Found 39 images belonging to 2 classes.\n",
            "Found 39 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-12-24 19:22:41.603259: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2019-12-24 19:22:41.608022: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n",
            "2019-12-24 19:22:41.608206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5f7db80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-24 19:22:41.608256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-24 19:22:41.610039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-24 19:22:41.706674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:22:41.707354: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5f7dd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-24 19:22:41.707385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2019-12-24 19:22:41.707550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:22:41.708039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-24 19:22:41.708342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-24 19:22:41.709742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-24 19:22:41.711200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-24 19:22:41.711524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-24 19:22:41.712882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-24 19:22:41.713604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-24 19:22:41.716646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-24 19:22:41.716745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:22:41.717325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:22:41.717858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-24 19:22:41.717908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-24 19:22:41.719100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-24 19:22:41.719125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-24 19:22:41.719135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-24 19:22:41.719298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:22:41.719863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:22:41.720446: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-24 19:22:41.720483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "[INFO] compiling model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "[INFO] training head...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "2019-12-24 19:22:43.159335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-24 19:22:43.376156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "91/91 [==============================] - 4s 48ms/step - loss: 7.2201 - acc: 0.4890 - val_loss: 8.4623 - val_acc: 0.4737\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 8.2600 - val_acc: 0.4865\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 6.5957 - acc: 0.5385 - val_loss: 7.1543 - val_acc: 0.4865\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 6.1072 - acc: 0.5769 - val_loss: 6.6731 - val_acc: 0.5676\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 3s 27ms/step - loss: 7.4360 - acc: 0.5220 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 6.9207 - acc: 0.5659 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 6.9042 - acc: 0.5659 - val_loss: 6.8941 - val_acc: 0.5676\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 6.1438 - acc: 0.5934 - val_loss: 6.5309 - val_acc: 0.5676\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 5.9583 - acc: 0.5989 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 7.0156 - acc: 0.5495 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 6.9200 - acc: 0.5659 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 7.5517 - val_acc: 0.5263\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 6.9200 - acc: 0.5659 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 3s 27ms/step - loss: 6.9201 - acc: 0.5659 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 6.9422 - acc: 0.5604 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 7.0076 - acc: 0.5604 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 6.9419 - acc: 0.5604 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 6.7457 - acc: 0.5769 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 6.8325 - acc: 0.5714 - val_loss: 7.7558 - val_acc: 0.5135\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 6.6760 - acc: 0.5714 - val_loss: 5.6014 - val_acc: 0.6486\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 5.9104 - acc: 0.6099 - val_loss: 4.2189 - val_acc: 0.7297\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 5.4906 - acc: 0.6484 - val_loss: 5.6342 - val_acc: 0.5946\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 5.0432 - acc: 0.6758 - val_loss: 4.3247 - val_acc: 0.7297\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 5.6667 - acc: 0.6319 - val_loss: 6.2469 - val_acc: 0.5946\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 5.7920 - acc: 0.6319 - val_loss: 4.1265 - val_acc: 0.7297\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 5.7583 - acc: 0.6319 - val_loss: 4.5621 - val_acc: 0.7027\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 6.4247 - acc: 0.5879 - val_loss: 6.8940 - val_acc: 0.5676\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 6.8258 - acc: 0.5714 - val_loss: 5.6497 - val_acc: 0.6216\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 6.3567 - acc: 0.5934 - val_loss: 5.8735 - val_acc: 0.6316\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 5.8840 - acc: 0.6264 - val_loss: 6.0323 - val_acc: 0.6216\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 5.5456 - acc: 0.6374 - val_loss: 4.0156 - val_acc: 0.7297\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 5.7649 - acc: 0.6319 - val_loss: 5.2603 - val_acc: 0.6486\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 6.5266 - acc: 0.5879 - val_loss: 6.1891 - val_acc: 0.5676\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 6.2953 - acc: 0.5934 - val_loss: 6.1537 - val_acc: 0.5946\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 6.2349 - acc: 0.6099 - val_loss: 6.2389 - val_acc: 0.5946\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 6.4745 - acc: 0.5824 - val_loss: 6.1026 - val_acc: 0.5946\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 6.8095 - acc: 0.5714 - val_loss: 6.5766 - val_acc: 0.5676\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 7.5355 - acc: 0.5220 - val_loss: 5.7070 - val_acc: 0.6216\n",
            "[INFO] evaluating after fine-tuning network head...\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      1.00      0.63        18\n",
            "           1       0.00      0.00      0.00        21\n",
            "\n",
            "    accuracy                           0.46        39\n",
            "   macro avg       0.23      0.50      0.32        39\n",
            "weighted avg       0.21      0.46      0.29        39\n",
            "\n",
            "<keras.engine.input_layer.InputLayer object at 0x7fc495b00ef0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc4958c3e10>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc4958c3d68>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fc49563b550>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc495647b00>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc49564b748>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fc495652630>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc495659c18>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc49565dd30>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc495664c18>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fc4955ef400>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc4955f6ba8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc4955fccc0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc495601ba8>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fc49560e3c8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc495615b38>: True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc49561ac88>: True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fc495621b70>: True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fc4955ae390>: True\n",
            "[INFO] re-compiling model...\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 7.1381 - acc: 0.5495 - val_loss: 8.4832 - val_acc: 0.4737\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 7.4160 - acc: 0.5385 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 8.2101 - acc: 0.4890 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 7.5882 - acc: 0.5275 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 8.9994 - acc: 0.4396 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 8.6762 - acc: 0.4560 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 8.2769 - val_acc: 0.4865\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 2s 27ms/step - loss: 9.0332 - acc: 0.4396 - val_loss: 9.1481 - val_acc: 0.4324\n",
            "[INFO] evaluating after fine-tuning network...\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      1.00      0.63        18\n",
            "           1       0.00      0.00      0.00        21\n",
            "\n",
            "    accuracy                           0.46        39\n",
            "   macro avg       0.23      0.50      0.32        39\n",
            "weighted avg       0.21      0.46      0.29        39\n",
            "\n",
            "[INFO] serializing network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEAAmcYFjNak",
        "colab_type": "code",
        "outputId": "9884389d-3fa6-48db-a295-deb1d7d6e46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python predict.py --image '/content/fine-tuning-keras/Food-11/test/0/0.drishtiGS_007.png'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "[INFO] loading model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-12-24 19:42:14.027557: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2019-12-24 19:42:14.032721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n",
            "2019-12-24 19:42:14.032936: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7a66840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-24 19:42:14.032987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-24 19:42:14.035427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-24 19:42:14.139660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:42:14.140478: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7a66a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-24 19:42:14.140518: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2019-12-24 19:42:14.140684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:42:14.141180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-24 19:42:14.141512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-24 19:42:14.143020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-24 19:42:14.144615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-24 19:42:14.145013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-24 19:42:14.146569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-24 19:42:14.147350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-24 19:42:14.150380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-24 19:42:14.150489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:42:14.151054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:42:14.151551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-24 19:42:14.151609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-24 19:42:14.152599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-24 19:42:14.152621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-24 19:42:14.152630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-24 19:42:14.152731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:42:14.153269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-24 19:42:14.153777: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-24 19:42:14.153811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "2019-12-24 19:42:15.729216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-24 19:42:15.920402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ2-91T0n5sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/fine_tune_me.zip  /content/fine-tuning-keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Xk42Jzf3JG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbd1eb7e-0780-410c-a2ee-cd428593a577"
      },
      "source": [
        "\"\"\"\n",
        "Author: Abner Ayala-Acevedo\n",
        "This script based on examples provided in the keras documentation and a blog.\n",
        "\"Building powerful image classification models using very little data\"\n",
        "from blog.keras.io.\n",
        "Dataset: Subset of Kaggle Dataset\n",
        "https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "- cat pictures index 0-999 in data/train/cats\n",
        "- cat pictures index 1000-1400 in data/validation/cats\n",
        "- dogs pictures index 0-999 in data/train/dogs\n",
        "- dog pictures index 1000-1400 in data/validation/dogs\n",
        "Example: Dogs vs Cats (Directory Structure)\n",
        "data/\n",
        "    train/\n",
        "        dogs/\n",
        "            dog001.jpg\n",
        "            dog002.jpg\n",
        "            ...\n",
        "        cats/\n",
        "            cat001.jpg\n",
        "            cat002.jpg\n",
        "            ...\n",
        "    validation/\n",
        "        dogs/\n",
        "            dog001.jpg\n",
        "            dog002.jpg\n",
        "            ...\n",
        "        cats/\n",
        "            cat001.jpg\n",
        "            cat002.jpg\n",
        "            ...\n",
        "Example has 1000 training examples for each class, and 400 validation examples for each class.\n",
        "The data folder already contains the dogs vs cat data you simply need to run script. For the dogs_cats classification\n",
        "you can find a model already trained in the model folder. Feel free to create your own data.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.applications import *\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import backend as k\n",
        "import keras\n",
        "\n",
        "# fix seed for reproducible results (only works on CPU, not GPU)\n",
        "seed = 9\n",
        "np.random.seed(seed=seed)\n",
        "tf.set_random_seed(seed=seed)\n",
        "\n",
        "# hyper parameters for model\n",
        "nb_classes = 2  # number of classes\n",
        "based_model_last_block_layer_number = 126  # value is based on based model selected.\n",
        "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
        "batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
        "nb_epoch = 50  # number of iteration the algorithm gets trained.\n",
        "learn_rate = 1e-4  # sgd learning rate\n",
        "momentum = .9  # sgd momentum to avoid local minimum\n",
        "transformation_ratio = .05  # how aggressive will be the data augmentation/transformation\n",
        "nb_train_samples = 2000  # Total number of train samples. NOT including augmented images\n",
        "nb_validation_samples = 800  # Total number of train samples. NOT including augmented images.\n",
        "\n",
        "\n",
        "def train(train_data_dir, validation_data_dir, model_path):\n",
        "    # Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n",
        "    # base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
        "    \n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (3, img_width, img_height)\n",
        "    else:\n",
        "        input_shape = (img_width, img_height, 3)\n",
        "    \n",
        "    base_model = InceptionV3(input_shape=input_shape, weights='imagenet', include_top=False)\n",
        "\n",
        "    # # Top Model Block\n",
        "    # x = base_model.output\n",
        "    # x = GlobalAveragePooling2D()(x)\n",
        "    # predictions = Dense(nb_classes, activation='softmax')(x)\n",
        "    \n",
        "    # add a global spatial average pooling layer\n",
        "    # x = base_model.output\n",
        "    # x = GlobalAveragePooling2D()(x)\n",
        "    # # let's add a fully-connected layer\n",
        "    # x = Dense(1024, activation='relu', name='fc1')(x)\n",
        "    \n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    predictions = Dense(nb_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # add your top layer block to your base model\n",
        "    model = Model(base_model.input, predictions)\n",
        "    print(model.summary())\n",
        "\n",
        "    # # let's visualize layer names and layer indices to see how many layers/blocks to re-train\n",
        "    # # uncomment when choosing based_model_last_block_layer\n",
        "    # for i, layer in enumerate(model.layers):\n",
        "    #     print(i, layer.name)\n",
        "\n",
        "    # first: train only the top layers (which were randomly initialized)\n",
        "    # i.e. freeze all layers of the based model that is already pre-trained.\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n",
        "    # To save augmentations un-comment save lines and add to your flow parameters.\n",
        "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                       rotation_range=transformation_ratio,\n",
        "                                       shear_range=transformation_ratio,\n",
        "                                       zoom_range=transformation_ratio,\n",
        "                                       cval=transformation_ratio,\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True)\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # os.makedirs(os.path.join(os.path.abspath(train_data_dir), 'preview'), exist_ok=True)\n",
        "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                        target_size=[img_width, img_height],\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='categorical')\n",
        "    # save_to_dir=os.path.join(os.path.abspath(train_data_dir), '../preview')\n",
        "    # save_prefix='aug',\n",
        "    # save_format='jpeg')\n",
        "    # use the above 3 commented lines if you want to save and look at how the data augmentations look like\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                                  target_size=[img_width, img_height],\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical')\n",
        "\n",
        "    model.compile(optimizer='nadam',\n",
        "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
        "\n",
        "    top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n",
        "    callbacks_list = [\n",
        "        ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
        "        EarlyStopping(monitor='val_acc', patience=5, verbose=0),\n",
        "        keras.callbacks.TensorBoard(log_dir='tensorboard/inception-v3-train-top-layer', histogram_freq=0, write_graph=False, write_images=False)\n",
        "    ]\n",
        "\n",
        "    # Train Simple CNN\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=nb_train_samples // batch_size,\n",
        "                        epochs=nb_epoch / 5,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=nb_validation_samples // batch_size,\n",
        "                        callbacks=callbacks_list)\n",
        "\n",
        "    # verbose\n",
        "    print(\"\\nStarting to Fine Tune Model\\n\")\n",
        "\n",
        "    # add the best weights from the train top model\n",
        "    # at this point we have the pre-train weights of the base model and the trained weight of the new/added top model\n",
        "    # we re-load model weights to ensure the best epoch is selected and not the last one.\n",
        "    model.load_weights(top_weights_path)\n",
        "\n",
        "    # based_model_last_block_layer_number points to the layer in your model you want to train.\n",
        "    # For example if you want to train the last block of a 19 layer VGG16 model this should be 15\n",
        "    # If you want to train the last Two blocks of an Inception model it should be 172\n",
        "    # layers before this number will used the pre-trained weights, layers above and including this number\n",
        "    # will be re-trained based on the new data.\n",
        "    for layer in model.layers[:based_model_last_block_layer_number]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[based_model_last_block_layer_number:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # compile the model with a SGD/momentum optimizer\n",
        "    # and a very slow learning rate.\n",
        "    model.compile(optimizer='nadam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "                  \n",
        "    \n",
        "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
        "    final_weights_path = os.path.join(os.path.abspath(model_path), 'model_weights.h5')\n",
        "    callbacks_list = [\n",
        "        ModelCheckpoint(final_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
        "        EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
        "        keras.callbacks.TensorBoard(log_dir='tensorboard/inception-v3-fine-tune', histogram_freq=0, write_graph=False, write_images=False)\n",
        "    ]\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # fine-tune the model\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=nb_train_samples // batch_size,\n",
        "                        epochs=nb_epoch,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=nb_validation_samples // batch_size,\n",
        "                        callbacks=callbacks_list)\n",
        "\n",
        "    # save model\n",
        "    model_json = model.to_json()\n",
        "    with open(os.path.join(os.path.abspath(model_path), 'model.json'), 'w') as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "\n",
        "train('/content/fine-tuning-keras/Food-11/train', '/content/fine-tuning-keras/Food-11/valid', '.')\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     if not len(sys.argv) == 3:\n",
        "#         print('Arguments must match:\\npython code/fine_tune.py <data_dir/> <model_dir/>')\n",
        "#         print('Example: python code/fine_tune.py data/dogs_cats/ model/dog_cats/')\n",
        "#         sys.exit(2)\n",
        "#     else:\n",
        "#         data_dir = os.path.abspath(sys.argv[1])\n",
        "#         train_dir = os.path.join(os.path.abspath(data_dir), 'train')  # Inside, each class should have it's own folder\n",
        "#         validation_dir = os.path.join(os.path.abspath(data_dir), 'validation')  # each class should have it's own folder\n",
        "#         model_dir = os.path.abspath(sys.argv[2])\n",
        "\n",
        "#         os.makedirs(os.path.join(os.path.abspath(data_dir), 'preview'), exist_ok=True)\n",
        "#         os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "#     train(train_dir, validation_dir, model_dir)  # train model\n",
        "\n",
        "#     # release memory\n",
        "#     k.clear_session()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 4s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 256)          524544      global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           fc1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 2)            514         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 22,327,842\n",
            "Trainable params: 22,293,410\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Found 182 images belonging to 2 classes.\n",
            "Found 39 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1128: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/10\n",
            "62/62 [==============================] - 42s 678ms/step - loss: 0.7767 - acc: 0.6257 - val_loss: 0.7581 - val_acc: 0.4620\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.46200, saving model to /content/fine-tuning-keras/top_model_weights.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/10\n",
            "62/62 [==============================] - 35s 564ms/step - loss: 0.5622 - acc: 0.7266 - val_loss: 0.7037 - val_acc: 0.5895\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.46200 to 0.58947, saving model to /content/fine-tuning-keras/top_model_weights.h5\n",
            "Epoch 3/10\n",
            "62/62 [==============================] - 36s 579ms/step - loss: 0.4829 - acc: 0.7599 - val_loss: 0.6850 - val_acc: 0.6640\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.58947 to 0.66400, saving model to /content/fine-tuning-keras/top_model_weights.h5\n",
            "Epoch 4/10\n",
            "62/62 [==============================] - 36s 581ms/step - loss: 0.4626 - acc: 0.7707 - val_loss: 0.9924 - val_acc: 0.5347\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.66400\n",
            "Epoch 5/10\n",
            "62/62 [==============================] - 36s 583ms/step - loss: 0.4328 - acc: 0.8077 - val_loss: 0.7898 - val_acc: 0.5660\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.66400\n",
            "Epoch 6/10\n",
            "62/62 [==============================] - 37s 589ms/step - loss: 0.4393 - acc: 0.7880 - val_loss: 0.8927 - val_acc: 0.4589\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.66400\n",
            "Epoch 7/10\n",
            "62/62 [==============================] - 37s 596ms/step - loss: 0.4123 - acc: 0.8109 - val_loss: 0.7937 - val_acc: 0.5140\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.66400\n",
            "Epoch 8/10\n",
            "62/62 [==============================] - 36s 575ms/step - loss: 0.3824 - acc: 0.8295 - val_loss: 1.1842 - val_acc: 0.5684\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.66400\n",
            "\n",
            "Starting to Fine Tune Model\n",
            "\n",
            "Epoch 1/50\n",
            "62/62 [==============================] - 50s 800ms/step - loss: 0.4959 - acc: 0.7882 - val_loss: 4.5679 - val_acc: 0.6400\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.64000, saving model to /content/fine-tuning-keras/model_weights.h5\n",
            "Epoch 2/50\n",
            "62/62 [==============================] - 38s 615ms/step - loss: 0.1975 - acc: 0.9315 - val_loss: 4.5309 - val_acc: 0.6147\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.64000\n",
            "Epoch 3/50\n",
            "62/62 [==============================] - 38s 621ms/step - loss: 0.2115 - acc: 0.9328 - val_loss: 1.2944 - val_acc: 0.4900\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.64000\n",
            "Epoch 4/50\n",
            "62/62 [==============================] - 38s 612ms/step - loss: 0.1039 - acc: 0.9609 - val_loss: 1.8133 - val_acc: 0.6632\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.64000 to 0.66316, saving model to /content/fine-tuning-keras/model_weights.h5\n",
            "Epoch 5/50\n",
            "62/62 [==============================] - 37s 604ms/step - loss: 0.0469 - acc: 0.9868 - val_loss: 1.1089 - val_acc: 0.7960\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.66316 to 0.79600, saving model to /content/fine-tuning-keras/model_weights.h5\n",
            "Epoch 6/50\n",
            "62/62 [==============================] - 38s 620ms/step - loss: 0.0158 - acc: 0.9960 - val_loss: 1.1531 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79600\n",
            "Epoch 7/50\n",
            "62/62 [==============================] - 38s 619ms/step - loss: 0.0255 - acc: 0.9910 - val_loss: 1.6027 - val_acc: 0.7940\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.79600\n",
            "Epoch 8/50\n",
            "62/62 [==============================] - 38s 609ms/step - loss: 0.0629 - acc: 0.9793 - val_loss: 1.4049 - val_acc: 0.7684\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.79600\n",
            "Epoch 9/50\n",
            "62/62 [==============================] - 39s 623ms/step - loss: 0.0314 - acc: 0.9930 - val_loss: 1.6228 - val_acc: 0.7660\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.79600\n",
            "Epoch 10/50\n",
            "62/62 [==============================] - 38s 610ms/step - loss: 0.0205 - acc: 0.9947 - val_loss: 1.8280 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.79600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYSXfSoyhtrX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "23bfe790-e9a8-497c-9837-5dd9a84e6fe5"
      },
      "source": [
        "# USAGE\n",
        "# python predict.py --image dataset/evaluation/Egg/3_137.jpg \n",
        "\n",
        "# import the necessary packages\n",
        "from keras.models import load_model\n",
        "#from pyimagesearch import config\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "# construct the argument parser and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-i\", \"--image\", type=str, required=True,\n",
        "\t#help=\"path to our input image\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# load the input image and then clone it so we can draw on it later\n",
        "image = cv2.imread(\"/content/fine-tuning-keras/Food-11/test/1/1.G-11-R.png\")\n",
        "output = image.copy()\n",
        "output = imutils.resize(output, width=400)\n",
        "\n",
        "# our model was trained on RGB ordered images but OpenCV represents\n",
        "# images in BGR order, so swap the channels, and then resize to\n",
        "# 224x224 (the input dimensions for VGG16)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = cv2.resize(image, (299, 299))\n",
        "\n",
        "# convert the image to a floating point data type and perform mean\n",
        "# subtraction\n",
        "image = image.astype(\"float32\")\n",
        "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
        "image -= mean\n",
        "\n",
        "# load the trained model from disk\n",
        "print(\"[INFO] loading model...\")\n",
        "model = load_model('/content/fine-tuning-keras/top_model_weights.h5')\n",
        "\n",
        "# pass the image through the network to obtain our predictions\n",
        "preds = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "i = np.argmax(preds)\n",
        "#label = class_mode[i]\n",
        "\n",
        "# draw the prediction on the output image\n",
        "text = \" {:.2f}%\".format(preds[i] * 100)\n",
        "cv2.putText(output, text, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "\t(0, 255, 0), 2)\n",
        "\n",
        "# show the output image\n",
        "cv2.imwrite('/content/output.png',output)\n",
        "#cv2.imshow(\"Output\", output)\n",
        "#cv2.waitKey(0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}